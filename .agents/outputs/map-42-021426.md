# MAP: Issue #42 -- PDFRouter orchestrator and public API

**Date:** 2026-02-14
**Issue:** #42 -- Implement PDFRouter orchestrator and public API (router.py)
**SPEC sections:** 17.1, 17.2, 17.3, 18.1, 20, 21

---

## 1. Problem Summary

Implement the top-level `PDFRouter` class in `router.py` that orchestrates the entire PDF processing pipeline: security scan, ingest key computation, document opening/profiling, language detection, tiered classification with LLM outage resilience, routing to the correct processor, result assembly, and PII-safe logging. Also implement `process_batch()` with `ProcessPoolExecutor` isolation, the `create_default_router()` factory, and update `__init__.py` with public API exports per SPEC section 21.1.

---

## 2. Codebase Findings

### 2.1 Files to Create
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/src/ingestkit_pdf/router.py`
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/tests/test_router.py`

### 2.2 Files to Modify
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/src/ingestkit_pdf/__init__.py` -- add all SPEC section 21.1 exports

### 2.3 All Dependency Modules (Verified Present)

| Module | Location | Key Classes/Functions | Status |
|--------|----------|----------------------|--------|
| `security.py` | `src/ingestkit_pdf/security.py` | `PDFSecurityScanner.scan() -> (DocumentMetadata, list[IngestError])` | Present |
| `config.py` | `src/ingestkit_pdf/config.py` | `PDFProcessorConfig` (all params) | Present |
| `models.py` | `src/ingestkit_pdf/models.py` | `ProcessingResult`, `DocumentProfile`, `ClassificationResult`, `ClassificationStageResult`, `ParseStageResult`, `OCRStageResult`, `PDFType`, `PageType`, `IngestionMethod`, etc. | Present |
| `errors.py` | `src/ingestkit_pdf/errors.py` | `ErrorCode`, `IngestError` | Present |
| `protocols.py` | `src/ingestkit_pdf/protocols.py` | Re-exports `VectorStoreBackend`, `StructuredDBBackend`, `LLMBackend`, `EmbeddingBackend` from core | Present |
| `inspector.py` | `src/ingestkit_pdf/inspector.py` | `PDFInspector.classify(profile) -> ClassificationResult` | Present |
| `llm_classifier.py` | `src/ingestkit_pdf/llm_classifier.py` | `PDFLLMClassifier.classify(profile, tier) -> ClassificationResult`. Raises `ConnectionError` for outage. | Present |
| `processors/text_extractor.py` | `src/ingestkit_pdf/processors/text_extractor.py` | `TextExtractor.process(file_path, profile, ingest_key, ingest_run_id, parse_result, classification_result, classification) -> ProcessingResult` | Present |
| `processors/ocr_processor.py` | `src/ingestkit_pdf/processors/ocr_processor.py` | `OCRProcessor.process(file_path, profile, pages, ingest_key, ingest_run_id, parse_result, classification_result, classification) -> ProcessingResult` | Present |
| `processors/table_extractor.py` | `src/ingestkit_pdf/processors/table_extractor.py` | `TableExtractor.extract_tables(file_path, page_numbers, ingest_key, ingest_run_id) -> TableExtractionResult` | Present |
| `quality.py` | `src/ingestkit_pdf/quality.py` | `QualityAssessor.assess_page()`, `assess_document()` | Present |
| `utils/language.py` | `src/ingestkit_pdf/utils/language.py` | `detect_language(text) -> (lang, confidence)` | Present |
| `utils/layout_analysis.py` | `src/ingestkit_pdf/utils/layout_analysis.py` | Multi-column layout detection | Present |
| `ingestkit_core.idempotency` | core package | `compute_ingest_key(file_path, parser_version, tenant_id, source_uri) -> IngestKey` | Present |
| `ingestkit_core.models` | core package | `IngestKey`, `WrittenArtifacts`, `ClassificationTier`, `EmbedStageResult`, `ChunkPayload` | Present |
| **ComplexProcessor** | -- | **NOT YET IMPLEMENTED** -- no `complex_processor.py` exists | **MISSING** |

### 2.4 Critical Finding: ComplexProcessor Does Not Exist

The SPEC section 17.1 step 11 routes `COMPLEX` type to `ComplexProcessor.process()`, but this processor has not been implemented. The router must handle this gracefully. Options:
1. **Stub routing**: Route COMPLEX to a stub that returns a result with zero chunks and an appropriate warning/error code.
2. **Fallback routing**: Route COMPLEX to TextExtractor as a degraded fallback (with a warning).

**Recommendation**: Since this is a Phase 1 delivery and ComplexProcessor is listed as a separate issue, the router should accept an optional `complex_processor` parameter (defaulting to `None`) and when it is `None` and a COMPLEX classification occurs, either:
- Use TextExtractor as a fallback with a warning, OR
- Return a result indicating the processing path is not yet available.

Based on the ExcelRouter pattern (which always has all three processors), the cleanest approach is to accept it as an optional parameter and raise a clear error if COMPLEX is classified but no complex_processor is provided.

### 2.5 Processor API Signatures (Critical -- COMPONENT_API Pattern)

**TextExtractor.process():**
```python
def process(
    self,
    file_path: str,
    profile: DocumentProfile,
    ingest_key: str,
    ingest_run_id: str,
    parse_result: ParseStageResult,
    classification_result: ClassificationStageResult,
    classification: ClassificationResult,
) -> ProcessingResult:
```

**OCRProcessor.process():**
```python
def process(
    self,
    file_path: str,
    profile: DocumentProfile,
    pages: list[int] | None,   # <-- extra param vs TextExtractor
    ingest_key: str,
    ingest_run_id: str,
    parse_result: ParseStageResult,
    classification_result: ClassificationStageResult,
    classification: ClassificationResult,
) -> ProcessingResult:
```

**Key difference**: OCRProcessor takes an extra `pages: list[int] | None` parameter. The router must pass `None` for full-document OCR (auto-select pages from profile).

### 2.6 Security Scanner API

```python
PDFSecurityScanner.scan(file_path: str) -> tuple[DocumentMetadata, list[IngestError]]
```
Fatal errors have codes starting with `E_`. Router must check for any `E_*` errors and return immediately.

### 2.7 Inspector and LLM Classifier APIs

- `PDFInspector(config).classify(profile) -> ClassificationResult`
  - Returns `confidence=0.0` for inconclusive results
  - Always produces a result (no exceptions for classification logic)

- `PDFLLMClassifier(llm, config).classify(profile, tier) -> ClassificationResult`
  - Raises `ConnectionError` when LLM backend is unreachable (propagated for router to catch)
  - Raises `TimeoutError` for timeouts
  - Returns `confidence=0.0` when all retries exhausted (fail-closed at classifier level)

### 2.8 LLM Outage Resilience Contract (SPEC section 5.2 + 10.6)

The router's `_classify()` method must implement:

1. **Always run Tier 1** -- zero external dependencies, always produces a result
2. **Tier 1 high confidence** -- if `confidence >= tier1_high_confidence_signals / 5` (i.e., 4/5 = 0.8 by default), skip LLM tiers
3. **Tier 2 attempt** -- wrapped in try/except for `ConnectionError`, `TimeoutError`
4. **Tier 3 escalation** -- if Tier 2 confidence < `tier2_confidence_threshold` (0.6) and `enable_tier3`
5. **On any LLM exception**: degrade to Tier 1 result with `degraded=True`, emit `W_LLM_UNAVAILABLE` + `W_CLASSIFICATION_DEGRADED`
6. **Key invariant**: `E_CLASSIFY_INCONCLUSIVE` only when Tier 1 cannot produce a usable result AND all LLM tiers also fail. LLM outage alone NEVER causes zero-chunk results.

### 2.9 Document Profiling (Steps 4-5)

The router needs to open the PDF with PyMuPDF and extract a `DocumentProfile`. This requires:
- Opening with `fitz.open()` (with repair attempt if corrupt)
- Per-page profiling: text length, word count, image count/coverage, table count, font info, form fields, multi-column detection
- Overall quality assessment via `QualityAssessor`
- Language detection via `detect_language()`

**Question**: Is there an existing profiler module? Looking at the codebase, there is NO dedicated `profiler.py` or `document_profiler.py`. The processors (TextExtractor, OCRProcessor) receive a pre-built `DocumentProfile` but never create one.

**This means the router must implement document profiling inline**, or we need to check if it's part of another issue. Given the issue description says "document opening/profiling", this is the router's responsibility.

The `DocumentProfile` model requires:
```python
DocumentProfile(
    file_path, file_size_bytes, page_count, content_hash,
    metadata: DocumentMetadata, pages: list[PageProfile],
    page_type_distribution: dict[str, int],
    detected_languages: list[str],
    has_toc: bool, toc_entries: list[tuple[int, str, int]] | None,
    overall_quality: ExtractionQuality,
    security_warnings: list[str],
)
```

And each `PageProfile` needs:
```python
PageProfile(
    page_number, text_length, word_count, image_count,
    image_coverage_ratio, table_count, font_count, font_names,
    has_form_fields, is_multi_column, page_type: PageType,
    extraction_quality: ExtractionQuality,
)
```

The router will need to build this from PyMuPDF page data. This is a significant chunk of code. It should be extracted into a private method `_build_document_profile()`.

### 2.10 Idempotency Key Computation

Uses `ingestkit_core.idempotency.compute_ingest_key()`:
```python
from ingestkit_core.idempotency import compute_ingest_key
key_obj = compute_ingest_key(file_path, parser_version, tenant_id, source_uri)
ingest_key = key_obj.key  # SHA256 hex digest
```

### 2.11 ProcessingResult Structure

```python
ProcessingResult(
    file_path: str,
    ingest_key: str,
    ingest_run_id: str,
    tenant_id: str | None,
    parse_result: ParseStageResult,
    classification_result: ClassificationStageResult,
    ocr_result: OCRStageResult | None,
    embed_result: EmbedStageResult | None,
    classification: ClassificationResult,
    ingestion_method: IngestionMethod,
    chunks_created: int,
    tables_created: int,
    tables: list[str],
    written: WrittenArtifacts,
    errors: list[str],
    warnings: list[str],
    error_details: list[IngestError],
    processing_time_seconds: float,
)
```

### 2.12 process_batch() Design (SPEC section 17.2 + 18.1)

- Uses `ProcessPoolExecutor` for process isolation
- Each document gets `config.per_document_timeout_seconds` as hard timeout
- Backend connections created per-worker (avoid cross-process sharing)
- Returns `list[ProcessingResult]` in same order as input

**Implementation note**: `ProcessPoolExecutor` requires picklable arguments. The PDFRouter instance itself is NOT picklable (has backend connections). The module-level approach from OCRProcessor is the pattern: define a module-level `_process_single_file()` function that accepts only serializable primitives/config, creates backends internally.

However, this creates a tension: backends must be created per-worker, but `process_batch()` needs to know the backend configuration. The SPEC says "Backend connections are created per-worker in `process_batch()`." This means:
- The worker function needs config to create backends
- `PDFProcessorConfig` is Pydantic and serializable
- But the concrete backend classes may not be importable in the worker if they have heavy dependencies

**Pragmatic approach**: For v1.0, `process_batch()` can use `ProcessPoolExecutor` with `concurrent.futures.Future.result(timeout=...)` per document. Each worker creates its own PDFRouter with fresh backend instances. But this requires the concrete backend classes to be available -- which is the `create_default_router` pattern.

**Alternative simpler approach** (matching ExcelRouter): Sequential processing with individual timeouts via subprocess. Or, even simpler for v1.0: process sequentially with per-document timeout via `signal.alarm` (Unix only) or thread-based timeout.

Given that the ExcelRouter's `process_batch()` is sequential (no process isolation), and the PDF SPEC explicitly requires process isolation, we should implement it with `ProcessPoolExecutor`. The worker function creates a fresh router per process.

### 2.13 create_default_router() Factory

Pattern matches ExcelRouter exactly. Needs:
- Default backends: Qdrant, SQLite, Ollama (LLM + Embedding)
- Lazy imports of concrete backends
- Overrides for all parameters

**Question**: Does ingestkit-pdf have a `backends.py` module? Let me check...

There is no `backends.py` in `ingestkit-pdf/src/ingestkit_pdf/`. The concrete backends live in `ingestkit-excel/src/ingestkit_excel/backends/`. Since `ingestkit-core` has the protocols, the PDF package should either:
1. Import backends from `ingestkit-excel` (bad -- creates circular dependency)
2. Have its own backends module
3. Import from `ingestkit-core` if backends were extracted there

Looking at the Excel package's backends imports in `create_default_router`:
```python
from ingestkit_excel.backends import OllamaEmbedding, OllamaLLM, QdrantVectorStore, SQLiteStructuredDB
```

For PDF, we need equivalent backends. Since backends are backend-agnostic (same protocol), the PDF factory should import from wherever the backends live. If `ingestkit-core` has them, use those. Otherwise, we need to create stubs or import from Excel.

**Decision**: The `create_default_router()` factory should attempt to import backends and raise `ImportError` with clear instructions if they're not available. We can import from a well-known location or make the factory accept explicit backend instances. For now, assume backends will be importable from a common location -- match the Excel pattern but log that backends need to be provided or installed.

### 2.14 __init__.py Public API (SPEC section 21.1)

Required exports per SPEC:
```python
from ingestkit_pdf.router import PDFRouter
from ingestkit_pdf.config import PDFProcessorConfig
from ingestkit_pdf.models import (
    PDFType, PageType, ClassificationTier, ClassificationResult,
    ProcessingResult, ChunkPayload, PDFChunkMetadata,
    DocumentProfile, DocumentMetadata, PageProfile, ExtractionQuality,
    OCRResult, TableResult, WrittenArtifacts,
    ParseStageResult, ClassificationStageResult, OCRStageResult, EmbedStageResult,
)
from ingestkit_pdf.errors import ErrorCode, IngestError

def create_default_router(**overrides) -> PDFRouter:
    ...
```

### 2.15 PII-Safe Logging (SPEC section 20)

Logger name: `ingestkit_pdf`

**INFO level** per processed file:
```
ingestkit_pdf | file=handbook.pdf | ingest_key=b7c2... | tier=rule_based | type=text_native | confidence=0.92 | degraded=false | path=text_extraction | pages=87 | chunks=156 | tables=0 | ocr_pages=0 | time=4.2s
```

**WARNING level** for LLM outage:
```
ingestkit_pdf | file=mixed.pdf | code=W_LLM_UNAVAILABLE | detail=LLM backend unreachable (ConnectionError), classification degraded to Tier 1
```

**ERROR level** for fatal failures:
```
ingestkit_pdf | file=corrupt.pdf | code=E_PARSE_CORRUPT | detail=PyMuPDF open failed, repair attempt also failed
```

No raw text/chunk content in logs unless opt-in via config flags.

### 2.16 Existing Test Infrastructure (conftest.py)

All four mock backends are present:
- `MockLLMBackend` -- supports response queue and exception injection
- `MockVectorStoreBackend` -- tracks upserts, collections
- `MockEmbeddingBackend` -- returns fixed-dimension vectors
- `MockStructuredDBBackend` -- in-memory table storage

Factory helpers present:
- `_make_page_profile(**overrides)`
- `_make_document_profile(pages, **overrides)`
- `_make_extraction_quality(**overrides)`
- `_valid_response(type_, confidence, reasoning, page_types)`

---

## 3. Implementation Plan

### 3.1 router.py Structure

```python
class PDFRouter:
    __init__(self, vector_store, structured_db, llm, embedder, config=None)
    can_handle(self, file_path: str) -> bool
    process(self, file_path: str, source_uri: str | None = None) -> ProcessingResult
    process_batch(self, file_paths: list[str]) -> list[ProcessingResult]

    # Private methods:
    _build_document_profile(self, file_path, metadata, security_errors) -> DocumentProfile
    _build_page_profile(self, page: fitz.Page, page_number: int) -> PageProfile
    _classify(self, profile: DocumentProfile) -> tuple[ClassificationResult, list[str], list[str], list[IngestError]]
    _route_to_processor(self, classification, ...) -> ProcessingResult
    _build_error_result(self, file_path, ingest_key, ingest_run_id, errors, ...) -> ProcessingResult
    _merge_errors(self, result, errors) -> None

def create_default_router(**overrides) -> PDFRouter
```

### 3.2 process() Flow (15 Steps -- SPEC section 17.1)

1. Security scan via `PDFSecurityScanner.scan()`. Fatal errors -> return immediately with error result.
2. Compute `ingest_key` via `compute_ingest_key()`.
3. Generate `ingest_run_id` (UUID4).
4. Open document with PyMuPDF. If corrupt -> attempt repair -> if fails -> `E_PARSE_CORRUPT`.
5. Extract `DocumentProfile`: per-page `PageProfile` with quality assessment.
6. Detect language on pages with extractable text (if enabled).
7. Tier 1: `PDFInspector.classify()`.
8. If inconclusive -> Tier 2 (skipped if LLM unavailable per section 5.2).
9. If still low confidence -> Tier 3 (if enabled, skipped if LLM unavailable).
10. If all tiers fail and Tier 1 produced no usable result -> `E_CLASSIFY_INCONCLUSIVE`.
11. Route based on `ClassificationResult.pdf_type`.
12. Collect `WrittenArtifacts`.
13. Assemble `ProcessingResult`.
14. Log (PII-safe).
15. Return.

### 3.3 process_batch() Implementation

```python
def process_batch(self, file_paths: list[str]) -> list[ProcessingResult]:
    results = []
    with ProcessPoolExecutor(max_workers=...) as executor:
        futures = {
            executor.submit(_process_single, fp, config_dict): fp
            for fp in file_paths
        }
        for future in as_completed(futures):
            try:
                result = future.result(timeout=self._config.per_document_timeout_seconds)
                results.append(result)
            except TimeoutError:
                # Build error result for timed-out document
                ...
    # Re-sort to match input order
    return sorted_results
```

**Pickle constraint**: The module-level worker function must accept serializable args. Since `PDFProcessorConfig` is a Pydantic model (JSON-serializable), we can pass it. Backend creation happens inside the worker.

**Simplification for v1.0**: Given complexity, consider making `process_batch()` use sequential processing with per-document timeout enforcement via a thread wrapper (similar to how ExcelRouter does it sequentially but with the addition of timeout). This avoids the pickling/backend-recreation complexity while still providing timeout isolation. Process isolation can be added in v1.1.

### 3.4 Document Profiling Implementation

The router needs to build `DocumentProfile` from a PyMuPDF document. Key steps:

```python
def _build_document_profile(self, file_path, doc, metadata, security_warnings):
    content_hash = hashlib.sha256(Path(file_path).read_bytes()).hexdigest()
    pages = []
    for page_num in range(doc.page_count):
        page = doc[page_num]
        page_profile = self._build_page_profile(page, page_num + 1)
        pages.append(page_profile)

    # Page type distribution
    distribution = {}
    for p in pages:
        distribution[p.page_type.value] = distribution.get(p.page_type.value, 0) + 1

    # Language detection
    detected_languages = []
    if self._config.enable_language_detection:
        # Sample text from first few pages with text
        ...

    # TOC extraction
    toc = doc.get_toc()  # returns [(level, title, page_number), ...]

    # Overall quality
    quality_assessor = QualityAssessor(self._config)
    page_qualities = [p.extraction_quality for p in pages]
    overall_quality = quality_assessor.assess_document(page_qualities)

    return DocumentProfile(...)
```

### 3.5 Page Profiling

```python
def _build_page_profile(self, page, page_number):
    text = page.get_text()
    words = text.split()
    blocks = page.get_text("blocks")
    images = page.get_images()
    # Calculate image coverage from image blocks
    # Get font info from page.get_fonts()
    # Detect tables (simple heuristic: look for grid patterns)
    # Check form widgets
    # Multi-column detection via layout_analysis
    ...
```

### 3.6 Classification Tier Escalation

```python
def _classify(self, profile):
    errors, warnings, error_details = [], [], []

    # Tier 1: always runs
    tier1_result = self._inspector.classify(profile)

    # High confidence threshold from SPEC 10.6
    high_conf_threshold = self._config.tier1_high_confidence_signals / 5  # 4/5 = 0.8
    if tier1_result.confidence >= high_conf_threshold:
        return tier1_result, errors, warnings, error_details

    # Tier 2: attempt with LLM outage resilience
    try:
        tier2_result = self._llm_classifier.classify(profile, ClassificationTier.LLM_BASIC)
        if tier2_result.confidence >= self._config.tier2_confidence_threshold:
            return tier2_result, errors, warnings, error_details

        # Tier 3
        if self._config.enable_tier3:
            tier3_result = self._llm_classifier.classify(profile, ClassificationTier.LLM_REASONING)
            return tier3_result, errors, warnings, error_details

        return tier2_result, errors, warnings, error_details

    except (ConnectionError, TimeoutError) as exc:
        # LLM outage -- degrade to Tier 1
        warnings.extend([
            ErrorCode.W_LLM_UNAVAILABLE.value,
            ErrorCode.W_CLASSIFICATION_DEGRADED.value,
        ])
        error_details.append(IngestError(
            code=ErrorCode.W_LLM_UNAVAILABLE,
            message=f"LLM backend unreachable ({type(exc).__name__}), degraded to Tier 1",
            stage="classify",
            recoverable=True,
        ))
        # Mutate Tier 1 result
        degraded_result = tier1_result.model_copy(update={"degraded": True})
        return degraded_result, errors, warnings, error_details
```

---

## 4. Test Plan (test_router.py)

### 4.1 Test Categories

All tests marked `@pytest.mark.unit`.

| Test | Description |
|------|-------------|
| `test_can_handle_pdf_extension` | `.pdf`, `.PDF`, `.Pdf` -> True |
| `test_can_handle_non_pdf` | `.xlsx`, `.docx`, `.txt` -> False |
| `test_process_text_native_full_flow` | Happy path: text-native PDF, Tier 1 classification, TextExtractor routing |
| `test_process_scanned_full_flow` | Scanned PDF routes to OCRProcessor |
| `test_process_complex_no_processor` | Complex classification with no ComplexProcessor -> appropriate error/fallback |
| `test_security_scan_fatal_error_returns_immediately` | Invalid PDF -> immediate error result with E_SECURITY_INVALID_PDF |
| `test_security_scan_warning_continues` | Owner-password only -> W_ENCRYPTED_OWNER_ONLY, processing continues |
| `test_classification_tier_escalation` | Tier 1 inconclusive -> Tier 2 -> Tier 3 |
| `test_llm_outage_degrades_to_tier1` | ConnectionError -> degraded=True, W_LLM_UNAVAILABLE, W_CLASSIFICATION_DEGRADED, chunks > 0 |
| `test_llm_timeout_degrades_to_tier1` | TimeoutError -> same degraded behavior |
| `test_classification_inconclusive_fail_closed` | All tiers fail -> E_CLASSIFY_INCONCLUSIVE, zero chunks |
| `test_process_batch_returns_all_results` | Multiple files -> results in order |
| `test_process_batch_timeout_isolation` | Slow file -> timeout error, other files succeed |
| `test_ingest_key_deterministic` | Same file -> same ingest_key |
| `test_ingest_key_includes_tenant_id` | tenant_id in config -> affects key |
| `test_pii_safe_logging_no_raw_text` | Verify no raw text in INFO logs |
| `test_create_default_router` | Factory creates valid PDFRouter |
| `test_create_default_router_with_overrides` | Config overrides passed through |
| `test_written_artifacts_populated` | Result has vector_point_ids, collection |
| `test_corrupt_pdf_repair_attempt` | Corrupt file -> repair attempt -> E_PARSE_CORRUPT if fails |

### 4.2 Mock Strategy

- Use existing `MockLLMBackend`, `MockVectorStoreBackend`, `MockEmbeddingBackend`, `MockStructuredDBBackend` from conftest.py
- For `process()` tests, need to mock `fitz.open()` and `PDFSecurityScanner.scan()` since tests cannot create real PDFs in unit tests
- Alternatively, use `conftest.py` helper to create minimal in-memory PDF fixtures via `fitz` or `reportlab`
- For `process_batch()` tests, mock the `process()` method directly to test isolation/timeout logic

### 4.3 Test Fixtures Needed

```python
@pytest.fixture
def pdf_router(mock_vector_store, mock_structured_db, mock_llm, mock_embedder, pdf_config):
    return PDFRouter(
        vector_store=mock_vector_store,
        structured_db=mock_structured_db,
        llm=mock_llm,
        embedder=mock_embedder,
        config=pdf_config,
    )
```

---

## 5. Risks and Decisions

### 5.1 ComplexProcessor Not Yet Implemented

**Risk**: SPEC requires routing COMPLEX type to `ComplexProcessor.process()`, but this module doesn't exist.

**Decision**: Accept an optional `complex_processor` parameter in `PDFRouter.__init__()`. When COMPLEX is classified and no complex_processor is provided, return a `ProcessingResult` with zero chunks and an appropriate error indicating the processing path is not yet available. This allows the router to be fully functional for TEXT_NATIVE and SCANNED types while being forward-compatible for COMPLEX.

### 5.2 Document Profiling Responsibility

**Risk**: No dedicated profiler module exists. The router must build `DocumentProfile` from raw PyMuPDF data.

**Decision**: Implement `_build_document_profile()` and `_build_page_profile()` as private methods on `PDFRouter`. These can be extracted into a separate `profiler.py` module later if needed. Key sub-tasks:
- Page text extraction via `page.get_text()`
- Image coverage calculation from `page.get_images()` and image bounding boxes
- Font enumeration via `page.get_fonts()`
- Table detection heuristic (count tables via text block analysis or pdfplumber)
- Form field detection via `page.widgets()`
- Multi-column detection using `LayoutAnalyzer` from `utils/layout_analysis.py`
- TOC extraction via `doc.get_toc()`

### 5.3 process_batch() Implementation Complexity

**Risk**: Full `ProcessPoolExecutor` with per-worker backend creation is complex and may have pickling issues.

**Decision for v1.0**: Implement `process_batch()` with `concurrent.futures.ProcessPoolExecutor` using a module-level worker function. The worker receives the file path and serialized config, creates its own backends and router internally. If this proves too complex during implementation, fall back to sequential processing with per-document timeout via a thread-based timeout wrapper (ThreadPoolExecutor with timeout on `.result()`).

### 5.4 Backend Imports for create_default_router()

**Risk**: No `backends.py` module exists in ingestkit-pdf.

**Decision**: The `create_default_router()` factory will attempt lazy imports of backends. If the backends package exists in `ingestkit-core` or a shared location, use that. Otherwise, the factory should raise `ImportError` with clear installation instructions. For testing, the factory is not needed (tests use mock backends directly).

### 5.5 Page Type Classification in Profiler

**Risk**: `PageProfile.page_type` needs to be set during profiling, but the `PDFInspector` is the component that classifies page types.

**Decision**: The profiler assigns a preliminary `page_type` based on simple heuristics (blank detection, image coverage). The `PDFInspector` then uses the full signal set to produce the authoritative classification. This matches the existing test fixtures which set `page_type` on `PageProfile` before passing to the inspector.

---

## 6. File-Level Implementation Details

### 6.1 router.py Imports

```python
from __future__ import annotations
import hashlib
import logging
import os
import time
import uuid
from concurrent.futures import ProcessPoolExecutor, as_completed
from pathlib import Path

import fitz  # PyMuPDF

from ingestkit_core.idempotency import compute_ingest_key
from ingestkit_core.models import ClassificationTier, WrittenArtifacts

from ingestkit_pdf.config import PDFProcessorConfig
from ingestkit_pdf.errors import ErrorCode, IngestError
from ingestkit_pdf.inspector import PDFInspector
from ingestkit_pdf.llm_classifier import PDFLLMClassifier
from ingestkit_pdf.models import (
    ClassificationResult, ClassificationStageResult, DocumentMetadata,
    DocumentProfile, ExtractionQuality, IngestionMethod, PageProfile,
    PageType, ParseStageResult, PDFType, ProcessingResult,
)
from ingestkit_pdf.processors.ocr_processor import OCRProcessor
from ingestkit_pdf.processors.text_extractor import TextExtractor
from ingestkit_pdf.protocols import (
    EmbeddingBackend, LLMBackend, StructuredDBBackend, VectorStoreBackend,
)
from ingestkit_pdf.quality import QualityAssessor
from ingestkit_pdf.security import PDFSecurityScanner
from ingestkit_pdf.utils.language import detect_language
from ingestkit_pdf.utils.layout_analysis import LayoutAnalyzer  # need to verify class name
```

### 6.2 __init__.py Final Exports

Per SPEC section 21.1, plus router and factory:
```python
from ingestkit_pdf.router import PDFRouter, create_default_router
from ingestkit_pdf.config import PDFProcessorConfig
from ingestkit_pdf.models import (
    PDFType, PageType, ClassificationTier, ClassificationResult,
    ProcessingResult, ChunkPayload, PDFChunkMetadata,
    DocumentProfile, DocumentMetadata, PageProfile, ExtractionQuality,
    OCRResult, TableResult, WrittenArtifacts,
    ParseStageResult, ClassificationStageResult, OCRStageResult, EmbedStageResult,
)
from ingestkit_pdf.errors import ErrorCode, IngestError
# Keep existing exports
from ingestkit_pdf.llm_classifier import LLMClassificationResponse, PDFLLMClassifier
from ingestkit_pdf.processors.ocr_processor import OCRProcessor
from ingestkit_pdf.processors.text_extractor import TextExtractor
```

---

## 7. Estimated Complexity

| Component | Lines (est.) | Complexity |
|-----------|-------------|------------|
| `PDFRouter.__init__` | 30 | Low |
| `PDFRouter.can_handle` | 3 | Trivial |
| `PDFRouter.process` (15-step flow) | 150 | High |
| `PDFRouter._build_document_profile` | 80 | Medium |
| `PDFRouter._build_page_profile` | 50 | Medium |
| `PDFRouter._classify` (tier escalation) | 60 | Medium |
| `PDFRouter.process_batch` | 40 | Medium |
| `create_default_router` | 50 | Low (pattern from Excel) |
| `test_router.py` | 400+ | High |
| `__init__.py` update | 40 | Low |
| **Total** | **~900** | -- |

---

## 8. Verification Checklist

- [ ] `PDFRouter` implements `FileHandler` protocol (duck typing: `can_handle()`, `process()`)
- [ ] 15-step `process()` flow matches SPEC section 17.1 exactly
- [ ] LLM outage resilience matches SPEC section 5.2 contract
- [ ] `process_batch()` provides process isolation per SPEC section 17.2
- [ ] `create_default_router()` matches SPEC section 21.1
- [ ] `__init__.py` exports match SPEC section 21.1
- [ ] PII-safe logging matches SPEC section 20 format
- [ ] All error codes from SPEC section 19 used correctly
- [ ] `test_llm_outage_degrades_to_tier1` test matches SPEC section 5.2 test contract
- [ ] No raw text in INFO/WARNING logs unless opt-in flags are set
- [ ] `tenant_id` propagated through all stages
- [ ] `ingest_key` deterministic and includes `parser_version`
