# MAP Artifact — Issue #40: Table Extractor

**Issue:** #40 — Implement table extractor (`processors/table_extractor.py`)
**SPEC Section:** 11.3 steps 2-3
**Complexity:** COMPLEX
**Date:** 2026-02-14

---

## 1. Investigation Summary

### 1.1 SPEC Requirements (Section 11.3, Steps 2-3)

**Step 2 — Table extraction** (via `processors/table_extractor.py`):
- Detect tables using `pdfplumber` on each page.
- For each table:
  - Extract as a pandas DataFrame.
  - If `<= table_max_rows_for_serialization` rows (default 20): serialize rows as natural language sentences, embed as chunks.
  - If `> table_min_rows_for_db` rows (default 20): load into `StructuredDBBackend` via `create_table_from_dataframe()`, embed a schema description.
- Tag with `content_type="table"`, `table_index`, `page_number`.

**Step 3 — Multi-page table stitching:**
- Compare column count and header text between last table on page N and first table on page N+1.
- If column count matches AND header similarity >= `table_continuation_column_match_threshold` (default 0.8): concatenate (skip repeated header on page N+1).
- Tag with `is_continuation=True` and shared `continuation_group_id`.
- Emit `W_TABLE_CONTINUATION` warning.

### 1.2 SPEC Test Requirements (Section 22.3)

| Module | Key test cases |
|--------|---------------|
| `table_extractor.py` | pdfplumber table detection; DataFrame conversion; serialization vs DB routing; continuation stitching |

Requirements traceability:
- **R-PC-2**: Table extraction — `test_table_extractor::test_pdfplumber_extraction` — Phase 1
- **R-PC-3**: Multi-page table stitching — `test_table_extractor::test_continuation_stitching` — Phase 1

---

## 2. Codebase Findings

### 2.1 File Inventory — Existing Files to Read/Use

| File | Path | Relevance |
|------|------|-----------|
| `models.py` | `packages/ingestkit-pdf/src/ingestkit_pdf/models.py` | `TableResult` model (lines 218-228), `PDFChunkMetadata` (lines 230-250), `ContentType.TABLE` enum |
| `protocols.py` | `packages/ingestkit-pdf/src/ingestkit_pdf/protocols.py` | Re-exports from core: `StructuredDBBackend`, `VectorStoreBackend`, `EmbeddingBackend` |
| `config.py` | `packages/ingestkit-pdf/src/ingestkit_pdf/config.py` | Table-related config fields (lines 86-89) |
| `errors.py` | `packages/ingestkit-pdf/src/ingestkit_pdf/errors.py` | `E_PROCESS_TABLE_EXTRACT` (line 53), `W_TABLE_CONTINUATION` (line 65) |
| `pyproject.toml` | `packages/ingestkit-pdf/pyproject.toml` | `pdfplumber>=0.10` already in dependencies (line 14) |
| `processors/__init__.py` | `packages/ingestkit-pdf/src/ingestkit_pdf/processors/__init__.py` | Empty — needs export |
| `conftest.py` | `packages/ingestkit-pdf/tests/conftest.py` | Has `MockLLMBackend`, factory helpers; needs mock StructuredDB/Vector/Embedding backends for table tests |
| `structured_db.py` (Excel) | `packages/ingestkit-excel/src/ingestkit_excel/processors/structured_db.py` | Reference pattern for DB writing, schema description generation, row serialization |

### 2.2 File Inventory — Files to Create

| File | Path | Purpose |
|------|------|---------|
| `table_extractor.py` | `packages/ingestkit-pdf/src/ingestkit_pdf/processors/table_extractor.py` | Main implementation |
| `test_table_extractor.py` | `packages/ingestkit-pdf/tests/test_table_extractor.py` | Unit tests |

### 2.3 Key Models

**TableResult** (from `models.py`):
```python
class TableResult(BaseModel):
    page_number: int
    table_index: int
    row_count: int
    col_count: int
    headers: list[str] | None = None
    is_continuation: bool = False
    continuation_group_id: str | None = None
```

**PDFChunkMetadata** (from `models.py`):
```python
class PDFChunkMetadata(BaseChunkMetadata):
    source_format: str = "pdf"
    page_numbers: list[int]
    ingest_run_id: str
    heading_path: list[str] | None = None
    content_type: str | None = None       # <-- set to "table"
    table_index: int | None = None        # <-- populated for table chunks
    # ... other fields
```

**ContentType.TABLE** = `"table"` (enum value)

### 2.4 Config Fields

```python
table_max_rows_for_serialization: int = 20   # <= this: NL serialization
table_min_rows_for_db: int = 20              # > this: StructuredDB
table_continuation_column_match_threshold: float = 0.8  # header similarity
```

Note: The thresholds are set so that a table with exactly 20 rows goes to NL serialization, and a table with 21+ rows goes to DB. There is NO gap — the boundary is clean.

### 2.5 Backend Protocols (from `ingestkit_core`)

**StructuredDBBackend:**
- `create_table_from_dataframe(table_name: str, df: pd.DataFrame) -> None`
- `drop_table(table_name: str) -> None`
- `table_exists(table_name: str) -> bool`
- `get_table_schema(table_name: str) -> dict`
- `get_connection_uri() -> str`

**VectorStoreBackend:**
- `upsert_chunks(collection: str, chunks: list[ChunkPayload]) -> int`
- `ensure_collection(collection: str, vector_size: int) -> None`

**EmbeddingBackend:**
- `embed(texts: list[str], timeout: float | None = None) -> list[list[float]]`
- `dimension() -> int`

### 2.6 Error Codes

- `E_PROCESS_TABLE_EXTRACT` — Error during table extraction (fatal per-table, not per-document)
- `W_TABLE_CONTINUATION` — Warning when multi-page table stitching occurs

### 2.7 Dependencies

- `pdfplumber>=0.10` — already in `pyproject.toml` dependencies
- `pandas>=2.0` — already in dependencies
- `pydantic>=2.0` — already in dependencies

---

## 3. Key Design Decisions

### 3.1 Public Interface

Based on the SPEC module inventory (line 156: "Shared: pdfplumber table detection/extraction"), the table extractor is used by `ComplexProcessor` but is a standalone module. It should be callable independently.

Proposed public interface:
```python
class TableExtractor:
    def __init__(
        self,
        structured_db: StructuredDBBackend | None,
        vector_store: VectorStoreBackend | None,
        embedder: EmbeddingBackend | None,
        config: PDFProcessorConfig,
    ) -> None: ...

    def extract_tables(
        self,
        file_path: str,
        page_numbers: list[int],
        ingest_key: str,
        ingest_run_id: str,
    ) -> TableExtractionResult: ...
```

Backends are optional because:
- Small tables (NL serialization) need `embedder` + `vector_store` but NOT `structured_db`
- Large tables need `structured_db` + `embedder` + `vector_store`
- For pure extraction (no DB/embedding), caller may pass None

### 3.2 Return Type

Need a result container:
```python
class TableExtractionResult(BaseModel):
    tables: list[TableResult]
    chunks: list[ChunkPayload]
    table_names: list[str]        # DB table names written
    warnings: list[str]
    errors: list[IngestError]
```

This is NOT in models.py yet — should be defined in table_extractor.py as an internal result type, or added to models.py if the ComplexProcessor needs it.

### 3.3 Multi-Page Table Stitching Algorithm

1. Process pages in order.
2. For each page, extract all tables via pdfplumber.
3. Compare the LAST table on page N with the FIRST table on page N+1:
   - Column count must match exactly.
   - Header similarity check: use `difflib.SequenceMatcher` on header strings.
   - If match >= `table_continuation_column_match_threshold` (0.8): merge.
4. When merging:
   - Skip the repeated header row on page N+1.
   - Concatenate DataFrames.
   - Assign shared `continuation_group_id` (UUID).
   - Set `is_continuation=True` on the continuation TableResult.
   - Emit `W_TABLE_CONTINUATION` warning.

### 3.4 Dual Routing Logic

For each extracted (possibly stitched) table DataFrame:
- If `len(df) <= config.table_max_rows_for_serialization`:
  - Serialize each row as NL sentence: `"In table '{name}', row {N}: {col} is {val}, ..."`
  - Embed all row sentences as chunks.
  - Tag `content_type="table"`, `table_index`, `page_numbers`.
- If `len(df) > config.table_min_rows_for_db`:
  - Write to StructuredDB via `create_table_from_dataframe()`.
  - Generate schema description (same pattern as Excel `structured_db.py`).
  - Embed schema description as a single chunk.
  - Tag `content_type="table"`, `table_index`, `page_numbers`.

### 3.5 Table Naming

Follow the Excel pattern from `structured_db.py`:
- `clean_name()` to sanitize (lowercase, alphanumeric + underscore).
- Deduplicate names.
- Format: `pdf_{ingest_key_prefix}_{page}_{table_index}` or similar to avoid collisions.

### 3.6 pdfplumber Usage Pattern

```python
import pdfplumber

with pdfplumber.open(file_path) as pdf:
    page = pdf.pages[page_number - 1]  # 0-indexed in pdfplumber
    tables = page.extract_tables()      # list of list-of-lists
    for i, table_data in enumerate(tables):
        df = pd.DataFrame(table_data[1:], columns=table_data[0])  # first row = headers
```

Important: pdfplumber pages are 0-indexed, but our `page_number` is 1-indexed.

### 3.7 Error Handling

- Per-table error handling: if one table fails extraction, log `E_PROCESS_TABLE_EXTRACT`, continue to next.
- Backend errors during DB write or embedding: catch, classify (following Excel pattern), record, continue.
- Empty tables (no rows after header): skip silently.

---

## 4. Dependencies and Blockers

| Dependency | Status | Notes |
|------------|--------|-------|
| `pdfplumber` | Available | In pyproject.toml dependencies |
| `pandas` | Available | In pyproject.toml dependencies |
| `TableResult` model | Available | In models.py lines 218-228 |
| `PDFChunkMetadata` | Available | In models.py lines 230-250 |
| `E_PROCESS_TABLE_EXTRACT` | Available | In errors.py line 53 |
| `W_TABLE_CONTINUATION` | Available | In errors.py line 65 |
| Config fields | Available | In config.py lines 86-89 |
| Backend protocols | Available | In ingestkit_core protocols.py |
| `ChunkPayload` | Available | In ingestkit_core models.py |
| `WrittenArtifacts` | Available | In ingestkit_core models.py |
| Mock backends for tests | Partial | `MockLLMBackend` exists in conftest.py; need `MockStructuredDBBackend`, `MockVectorStoreBackend`, `MockEmbeddingBackend` |
| `ComplexProcessor` | Not yet implemented | Table extractor is consumed by it, but can be built independently |

No hard blockers. All dependencies are available.

---

## 5. Risk Assessment

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|------------|
| pdfplumber fails on certain PDF table structures | Medium | Medium | Error handling per-table; return partial results |
| Header detection in pdfplumber unreliable (merged cells, empty headers) | Medium | Low | Fallback to `column_0`, `column_1`, etc. |
| Multi-page stitching false positives | Low | Medium | Threshold at 0.8 is conservative; log warnings |
| Mock backends not yet in conftest.py | Certain | Low | Create them as part of this issue |

---

## 6. Patterns from Excel Reference

The Excel `StructuredDBProcessor` (in `structured_db.py`) provides a proven pattern for:
1. Schema description generation (`_generate_schema_description`)
2. Row NL serialization (`_serialize_rows`) — format: `"In table '{name}', row {N}: {col} is {val}, ..."`
3. Chunk ID generation: `uuid5(NAMESPACE_URL, "{ingest_key}:{chunk_hash}")`
4. Chunk hash: `sha256(text.encode()).hexdigest()`
5. Batch embedding with configurable batch size
6. Backend error classification
7. WrittenArtifacts tracking

These patterns should be reused in the PDF table extractor to maintain consistency across the monorepo.

---

## 7. File Paths Summary

**Read (existing):**
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/src/ingestkit_pdf/models.py`
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/src/ingestkit_pdf/protocols.py`
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/src/ingestkit_pdf/config.py`
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/src/ingestkit_pdf/errors.py`
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/pyproject.toml`
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/src/ingestkit_pdf/processors/__init__.py`
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/tests/conftest.py`
- `/home/jjob/projects/ingestkit/packages/ingestkit-core/src/ingestkit_core/protocols.py`
- `/home/jjob/projects/ingestkit/packages/ingestkit-core/src/ingestkit_core/models.py`
- `/home/jjob/projects/ingestkit/packages/ingestkit-excel/src/ingestkit_excel/processors/structured_db.py`

**Create:**
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/src/ingestkit_pdf/processors/table_extractor.py`
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/tests/test_table_extractor.py`

**Edit:**
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/src/ingestkit_pdf/processors/__init__.py` — add TableExtractor export
- `/home/jjob/projects/ingestkit/packages/ingestkit-pdf/tests/conftest.py` — add mock backends (MockStructuredDBBackend, MockVectorStoreBackend, MockEmbeddingBackend)
