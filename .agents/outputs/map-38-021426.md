---
issue: 38
title: "Implement Path A Text Extractor"
complexity: COMPLEX
agent: MAP
date: 2026-02-14
spec_sections: "§11.1"
files_to_create:
  - src/ingestkit_pdf/processors/text_extractor.py
  - tests/test_text_extractor.py
files_to_modify:
  - src/ingestkit_pdf/processors/__init__.py
  - src/ingestkit_pdf/__init__.py
status: COMPLETE
---

# MAP Artifact — Issue #38: Path A Text Extractor

## Executive Summary

Issue #38 requires implementing `processors/text_extractor.py` as defined in SPEC.md section 11.1. This is the fast-path processor for text-native PDFs (Type A), which represents the majority of HR/IT documents. The processor extracts markdown via `pymupdf4llm.to_markdown()`, assesses quality with OCR fallback for low-quality pages, strips headers/footers, detects headings, skips TOC/blank pages, chunks the text, embeds chunks, and upserts to the vector store. The implementation follows the same processor pattern established by `ingestkit-excel`'s `StructuredDBProcessor`.

## Investigation Findings

### 1. SPEC §11.1 Requirements

**Input:** `DocumentProfile` + classification confirming Type A (text-native).

**10-Step Pipeline:**
1. Extract text using `pymupdf4llm.to_markdown()` with `header=False, footer=False` for built-in header/footer suppression.
2. If markdown quality is poor (quality score LOW), fall back to `page.get_text("blocks")` for block-level extraction with position data.
3. Run header/footer stripping (cross-page similarity algorithm from `utils/header_footer.py`) as a second pass.
4. Detect and skip TOC pages (high density of `...\d+` patterns).
5. Detect and skip blank pages.
6. Extract heading hierarchy: first `doc.get_toc()`, fallback to font-size-based inference from `page.get_text("dict")` spans.
7. Extract document-level metadata from `doc.metadata` and propagate to all chunks.
8. Chunk extracted markdown using configurable strategy (default: recursive character splitter respecting heading boundaries).
9. Embed chunks via `EmbeddingBackend`.
10. Upsert to `VectorStoreBackend` with `PDFChunkMetadata`.

**Public Interface (from SPEC):**
```python
class TextExtractor:
    def __init__(self, vector_store: VectorStoreBackend, embedder: EmbeddingBackend,
                 config: PDFProcessorConfig): ...
    def process(self, file_path: str, profile: DocumentProfile,
                ingest_key: str, ingest_run_id: str) -> ProcessingResult: ...
```

**Metadata per chunk:** `PDFChunkMetadata` with `ingestion_method="text_extraction"`, `page_numbers`, `heading_path`, `content_type`, `doc_title`, `doc_author`, `language`.

### 2. Existing Models (models.py)

| Model/Enum | Lines | Relevance |
|---|---|---|
| `PDFType.TEXT_NATIVE` | 43 | Classification check on input |
| `PageType` | 48-58 | `BLANK` and `TOC` for skip logic |
| `IngestionMethod.TEXT_EXTRACTION` | 64 | Value: `"text_extraction"` for chunk metadata |
| `ExtractionQuality` | 102-126 | Quality assessment with `.score` and `.grade` properties |
| `ExtractionQualityGrade.LOW` | 81 | Triggers OCR fallback |
| `DocumentProfile` | 172-187 | Input to `process()`, contains `metadata`, `pages`, `toc_entries`, `detected_languages` |
| `DocumentMetadata` | 151-169 | Provides `title`, `author`, `creation_date` for chunk metadata |
| `PDFChunkMetadata` | 230-249 | Extends `BaseChunkMetadata` with PDF-specific fields |
| `ProcessingResult` | 297-323 | Return type from `process()` |
| `ParseStageResult` | 257-266 | Required field in `ProcessingResult` |
| `ClassificationStageResult` | 268-278 | Required field in `ProcessingResult` |
| `EmbedStageResult` | core:65-70 | Optional field in `ProcessingResult` |
| `ChunkPayload` | core:101-107 | Vector store upsert payload |
| `WrittenArtifacts` | core:115-120 | Tracks written vector point IDs and collection |

### 3. Backend Protocols (protocols.py -> ingestkit_core)

| Protocol | Methods Used by Path A |
|---|---|
| `VectorStoreBackend` | `ensure_collection(collection, vector_size)`, `upsert_chunks(collection, chunks)` |
| `EmbeddingBackend` | `embed(texts, timeout)`, `dimension()` |

Note: `StructuredDBBackend` and `LLMBackend` are NOT needed by Path A (text extraction does not use DB or LLM).

### 4. Configuration Fields (config.py)

| Field | Type | Default | Usage in Path A |
|---|---|---|---|
| `tenant_id` | `str \| None` | `None` | Propagated to chunk metadata |
| `parser_version` | `str` | `"ingestkit_pdf:1.0.0"` | Chunk metadata |
| `auto_ocr_fallback` | `bool` | `True` | Step 2: gate for block-level fallback |
| `quality_min_printable_ratio` | `float` | `0.85` | Quality assessment |
| `quality_min_words_per_page` | `int` | `10` | Quality assessment |
| `header_footer_sample_pages` | `int` | `5` | Header/footer detector |
| `header_footer_zone_ratio` | `float` | `0.10` | Header/footer detector |
| `header_footer_similarity_threshold` | `float` | `0.7` | Header/footer detector |
| `heading_min_font_size_ratio` | `float` | `1.2` | Heading detector |
| `chunk_size_tokens` | `int` | `512` | Chunker |
| `chunk_overlap_tokens` | `int` | `50` | Chunker |
| `chunk_respect_headings` | `bool` | `True` | Chunker |
| `chunk_respect_tables` | `bool` | `True` | Chunker |
| `embedding_model` | `str` | `"nomic-embed-text"` | Not used directly (backend handles) |
| `embedding_dimension` | `int` | `768` | Not used directly (backend reports) |
| `embedding_batch_size` | `int` | `64` | Batch embedding loop |
| `default_collection` | `str` | `"helpdesk"` | Vector store collection name |
| `backend_timeout_seconds` | `float` | `30.0` | Embedding timeout |
| `enable_language_detection` | `bool` | `True` | Language detection on extracted text |
| `default_language` | `str` | `"en"` | Fallback language |
| `log_sample_text` | `bool` | `False` | PII-safe logging gate |
| `log_chunk_previews` | `bool` | `False` | Chunker debug logging gate |

### 5. Error/Warning Codes (errors.py)

| Code | Type | Usage in Path A |
|---|---|---|
| `W_PAGE_SKIPPED_BLANK` | Warning | Step 5: blank page skipped |
| `W_PAGE_SKIPPED_TOC` | Warning | Step 4: TOC page skipped |
| `W_QUALITY_LOW_NATIVE` | Warning | Step 2: quality is LOW, attempting block fallback |
| `W_OCR_FALLBACK` | Warning | Quality still low after block fallback |
| `E_PROCESS_CHUNK` | Error | Chunking failure |
| `E_PROCESS_HEADER_FOOTER` | Error | Header/footer detection failure |
| `E_BACKEND_VECTOR_TIMEOUT` | Error | Vector store timeout |
| `E_BACKEND_VECTOR_CONNECT` | Error | Vector store connection failure |
| `E_BACKEND_EMBED_TIMEOUT` | Error | Embedding timeout |
| `E_BACKEND_EMBED_CONNECT` | Error | Embedding connection failure |

### 6. Existing Utility Dependencies

**HeaderFooterDetector** (`utils/header_footer.py`):
- Constructor: `HeaderFooterDetector(config: PDFProcessorConfig)`
- `detect(doc: fitz.Document) -> tuple[list[str], list[str]]` -- returns `(header_patterns, footer_patterns)`
- `strip(text, page_number, headers, footers) -> str` -- removes matching lines from text

**HeadingDetector** (`utils/heading_detector.py`):
- Constructor: `HeadingDetector(config: PDFProcessorConfig)`
- `detect(doc: fitz.Document) -> list[tuple[int, str, int]]` -- returns `(level, title, page_number)` tuples
- `get_heading_path(page_number, position_y) -> list[str]` -- returns heading ancestry

**PDFChunker** (`utils/chunker.py`):
- Constructor: `PDFChunker(config: PDFProcessorConfig)`
- `chunk(text, headings, page_boundaries) -> list[dict]` -- returns dicts with `text`, `page_numbers`, `heading_path`, `content_type`, `chunk_index`, `chunk_hash`
- Note: chunker's headings parameter expects `(level, title, char_offset)` tuples (different from HeadingDetector's page-number-based output). Conversion needed.

**QualityAssessor** (`quality.py`):
- Constructor: `QualityAssessor(config: PDFProcessorConfig)`
- `assess_page(page_text, page_number) -> ExtractionQuality`
- `assess_document(page_qualities) -> ExtractionQuality`
- `needs_ocr_fallback(quality) -> bool`

**Language Detection** (`utils/language.py`):
- `detect_language(text, *, default_language="en") -> tuple[str, float]`

### 7. pymupdf4llm Availability

Confirmed in `pyproject.toml` line 13: `"pymupdf4llm>=0.0.10"` is a core dependency. Also `"pymupdf>=1.24"` (provides `fitz`). Both are required, not optional.

**pymupdf4llm.to_markdown() API:**
- `pymupdf4llm.to_markdown(doc, page_chunks=True)` returns list of dicts with `{"text": ..., "metadata": {"page": N}}`
- The `header=False, footer=False` parameters suppress built-in header/footer detection (per SPEC step 1)

### 8. Excel StructuredDBProcessor Pattern Reference

From `packages/ingestkit-excel/src/ingestkit_excel/processors/structured_db.py`:

**Key patterns to follow:**
- Constructor takes backends + config via DI: `__init__(self, vector_store, embedder, config)`
- `process()` is the single public method returning `ProcessingResult`
- Timing with `time.monotonic()`
- `source_uri = f"file://{Path(file_path).resolve().as_posix()}"`
- Error collection: `errors: list[str]`, `warnings: list[str]`, `error_details: list[IngestError]`
- `WrittenArtifacts` tracking for rollback support
- `EmbedStageResult` assembly at the end
- Batch embedding loop with `config.embedding_batch_size`
- Chunk ID generation: `uuid.uuid5(uuid.NAMESPACE_URL, f"{ingest_key}:{chunk_hash}")`
- Backend error classification helper: `_classify_backend_error(exc)`
- Per-item try/except with continue pattern

**Key difference from Excel:** Path A does NOT receive `parse_result`, `classification_result`, or `classification` as parameters. The SPEC signature is simpler: `process(file_path, profile, ingest_key, ingest_run_id)`. However, `ProcessingResult` requires these fields. The Router will provide them separately, or the TextExtractor must construct them internally. Looking at the Router flow (SPEC §17.1), the Router assembles `ProcessingResult` -- but the SPEC §11.1 shows `TextExtractor.process()` returns `ProcessingResult`. **Decision needed: see D1 below.**

### 9. ProcessingResult Assembly Requirements

`ProcessingResult` has these required fields:
- `file_path`, `ingest_key`, `ingest_run_id` -- passed in
- `tenant_id` -- from config
- `parse_result: ParseStageResult` -- must be constructed
- `classification_result: ClassificationStageResult` -- must be passed in or constructed
- `ocr_result: OCRStageResult | None` -- None for Path A (unless OCR fallback used)
- `embed_result: EmbedStageResult | None` -- constructed from embedding metrics
- `classification: ClassificationResult` -- must be passed in or constructed
- `ingestion_method: IngestionMethod` -- `IngestionMethod.TEXT_EXTRACTION`
- `chunks_created`, `tables_created`, `tables` -- computed
- `written: WrittenArtifacts` -- tracked during processing
- `errors`, `warnings`, `error_details` -- accumulated

## Key Decisions for PLAN

### D1: Process Signature — Classification Parameters

The SPEC §11.1 shows a minimal signature: `process(file_path, profile, ingest_key, ingest_run_id)`. However, `ProcessingResult` requires `parse_result`, `classification_result`, and `classification`. Two options:

**Option A (Recommended):** Follow the Excel pattern and accept these as additional parameters. The Router computes them before dispatching.

**Option B:** Construct them internally. This would duplicate classification logic.

**Decision: Option A.** Extend the SPEC signature to match the Excel pattern:
```python
def process(self, file_path, profile, ingest_key, ingest_run_id,
            parse_result, classification_result, classification) -> ProcessingResult
```

### D2: TOC Page Detection

SPEC says "high density of `...\d+` patterns". Implementation: a page is TOC if >30% of non-empty lines match `r'\.\s*\.{2,}\s*\d+'` or similar dot-leader + page-number pattern. This should be a private method `_is_toc_page(text) -> bool`.

### D3: Blank Page Detection

A page is blank if its stripped text is empty or word count is below `quality_min_words_per_page`. Check `page_text.strip() == ""` or `len(page_text.split()) < config.quality_min_words_per_page`.

### D4: Heading Offset Conversion

`HeadingDetector.detect()` returns `(level, title, page_number)` tuples. `PDFChunker.chunk()` expects `(level, title, char_offset)` tuples. The TextExtractor must map page-number-based headings to character-offset-based headings using page boundary tracking during text concatenation. Track cumulative character offset per page.

### D5: Block-Level Fallback (Step 2)

When quality is LOW, fall back to `page.get_text("blocks")` which returns tuples `(x0, y0, x1, y1, text, block_no, type)`. Filter for type==0 (text blocks), concatenate text. This requires opening the PDF with `fitz.open()` directly.

### D6: Document Opening

The TextExtractor needs access to the `fitz.Document` object for:
- `pymupdf4llm.to_markdown()` extraction
- `page.get_text("blocks")` fallback
- Header/footer detection
- Heading detection

Open `fitz.open(file_path)` at the start of `process()` and close via context manager.

### D7: Language Detection Integration

If `config.enable_language_detection`, detect language from the first non-blank page's text using `detect_language()`. Use the detected language for all chunk metadata. Fall back to `config.default_language`.

### D8: Test Strategy

Per SPEC §22.3, key test cases for `text_extractor.py`:
- Markdown extraction (mock `pymupdf4llm.to_markdown()`)
- Heading hierarchy extraction and propagation to chunks
- Header/footer stripping integration
- TOC page skipping with warning
- Blank page skipping with warning
- Chunk metadata correctness (all PDFChunkMetadata fields populated)
- Quality assessment and block-level fallback trigger
- Embedding batch loop
- Vector store upsert
- Error handling (backend failures)
- ProcessingResult assembly correctness

All tests mock `fitz`, `pymupdf4llm`, and backend protocols. No real PDFs needed for unit tests.

## Dependency Analysis

### Internal Dependencies (this module imports)

| Import | From | Purpose |
|---|---|---|
| `PDFProcessorConfig` | `config.py` | Constructor parameter |
| `ErrorCode`, `IngestError` | `errors.py` | Error reporting |
| `PDFChunkMetadata`, `ProcessingResult`, `ParseStageResult`, etc. | `models.py` | Data models |
| `IngestionMethod` | `models.py` | `TEXT_EXTRACTION` enum |
| `ExtractionQualityGrade` | `models.py` | Quality gate check |
| `VectorStoreBackend`, `EmbeddingBackend` | `protocols.py` | Backend protocols |
| `ChunkPayload`, `WrittenArtifacts`, `EmbedStageResult` | `ingestkit_core.models` (via `models.py`) | Core models |
| `HeaderFooterDetector` | `utils/header_footer.py` | Step 3 |
| `HeadingDetector` | `utils/heading_detector.py` | Step 6 |
| `PDFChunker` | `utils/chunker.py` | Step 8 |
| `QualityAssessor` | `quality.py` | Step 2 quality gate |
| `detect_language` | `utils/language.py` | Step 7 language detection |
| `fitz` (pymupdf) | External | PDF document access |
| `pymupdf4llm` | External | Markdown extraction |
| `hashlib`, `uuid`, `time`, `re`, `logging`, `pathlib` | stdlib | Utilities |

### Downstream Consumers

- `PDFRouter` (future, issue for router) will import and instantiate `TextExtractor`
- `__init__.py` should export `TextExtractor`

## File Inventory

### Files to Create

| File | Purpose | Est. Lines |
|---|---|---|
| `packages/ingestkit-pdf/src/ingestkit_pdf/processors/text_extractor.py` | Path A text extraction processor | ~350 |
| `packages/ingestkit-pdf/tests/test_text_extractor.py` | Unit tests for all public interface and edge cases | ~400 |

### Files to Modify

| File | Change |
|---|---|
| `packages/ingestkit-pdf/src/ingestkit_pdf/processors/__init__.py` | Export `TextExtractor` |
| `packages/ingestkit-pdf/src/ingestkit_pdf/__init__.py` | Add `TextExtractor` to public API |

### Files Read (Reference Only)

| File | What was extracted |
|---|---|
| `SPEC.md` §11.1 | Full Path A text extractor specification |
| `SPEC.md` §17.1 | Router flow showing how processor is invoked |
| `SPEC.md` §19 | Error handling table for Path A scenarios |
| `SPEC.md` §22.3 | Test coverage requirements for text_extractor.py |
| `models.py` | All data models, enums, ProcessingResult structure |
| `protocols.py` | VectorStoreBackend, EmbeddingBackend interfaces |
| `config.py` | All relevant config fields for Path A |
| `errors.py` | ErrorCode enum with all Path A codes |
| `quality.py` | QualityAssessor API and quality grade logic |
| `utils/header_footer.py` | HeaderFooterDetector.detect() and .strip() APIs |
| `utils/heading_detector.py` | HeadingDetector.detect() and .get_heading_path() APIs |
| `utils/chunker.py` | PDFChunker.chunk() API, heading offset format, chunk dict schema |
| `utils/language.py` | detect_language() API |
| `utils/__init__.py` | Current utility exports |
| `ingestkit_core/protocols.py` | Backend protocol method signatures |
| `ingestkit_core/models.py` | BaseChunkMetadata, ChunkPayload, WrittenArtifacts, EmbedStageResult |
| `ingestkit-excel/.../structured_db.py` | Processor pattern reference (DI, error handling, batch embedding) |
| `tests/conftest.py` | Test fixtures and mock patterns |
| `pyproject.toml` | Dependency list confirming pymupdf4llm availability |

---

AGENT_RETURN: .agents/outputs/map-38-021426.md
