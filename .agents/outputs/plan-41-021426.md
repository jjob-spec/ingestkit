---
issue: 41
agent: PLAN
date: 2026-02-14
complexity: COMPLEX
stack: backend
depends_on: [38, 39, 40, 30, 31, 32, 37]
---

# PLAN Artifact: Issue #41 -- Implement Path C Complex Processor

## Executive Summary

Issue #41 implements `ComplexProcessor` in `processors/complex_processor.py`, the Path C processor for hybrid/complex PDFs. It routes each page by its `PageType` (TEXT, SCANNED, TABLE_HEAVY, FORM, MIXED, BLANK, TOC, VECTOR_ONLY), delegates to the appropriate extraction method, runs header/footer stripping and heading detection across the full document, handles multi-column layout reordering, extracts AcroForm fields from FORM pages, batches TABLE_HEAVY pages through `TableExtractor`, assembles all per-page text into a single document, then chunks, embeds, and upserts. The implementation reuses existing utilities (HeaderFooterDetector, HeadingDetector, PDFChunker, LayoutAnalyzer, TableExtractor) and the module-level `_ocr_single_page()` function from `ocr_processor.py` for SCANNED/MIXED pages.

---

## File-by-File Implementation

---

### 1. CREATE: `packages/ingestkit-pdf/src/ingestkit_pdf/processors/complex_processor.py` (~450 lines)

#### 1a. Module Docstring and Imports

```python
"""Path C processor: complex/hybrid PDF with per-page routing.

Handles Type C PDFs by routing each page through the appropriate extraction
method based on its PageType, then assembling results into a single chunked,
embedded document.

Spec reference: SPEC.md section 11.3.
"""

from __future__ import annotations

import hashlib
import logging
import time
import uuid
from pathlib import Path
from typing import TYPE_CHECKING, Any

import fitz  # type: ignore[import-untyped]
import pymupdf4llm  # type: ignore[import-untyped]

from ingestkit_core.models import ChunkPayload, EmbedStageResult, WrittenArtifacts
from ingestkit_pdf.config import PDFProcessorConfig
from ingestkit_pdf.errors import ErrorCode, IngestError
from ingestkit_pdf.models import (
    ClassificationResult,
    ClassificationStageResult,
    ContentType,
    DocumentProfile,
    IngestionMethod,
    OCRResult,
    OCRStageResult,
    PageType,
    ParseStageResult,
    PDFChunkMetadata,
    ProcessingResult,
)
from ingestkit_pdf.processors.ocr_processor import _ocr_single_page
from ingestkit_pdf.processors.table_extractor import TableExtractor
from ingestkit_pdf.utils.chunker import PDFChunker
from ingestkit_pdf.utils.header_footer import HeaderFooterDetector
from ingestkit_pdf.utils.heading_detector import HeadingDetector
from ingestkit_pdf.utils.language import detect_language
from ingestkit_pdf.utils.layout_analysis import LayoutAnalyzer, extract_text_blocks

if TYPE_CHECKING:
    from ingestkit_core.protocols import (
        EmbeddingBackend,
        LLMBackend,
        StructuredDBBackend,
        VectorStoreBackend,
    )

logger = logging.getLogger("ingestkit_pdf.processors.complex_processor")
```

#### 1b. Class: `ComplexProcessor`

##### Constructor Signature

```python
class ComplexProcessor:
    """Path C processor: complex/hybrid PDF with per-page routing."""

    def __init__(
        self,
        vector_store: VectorStoreBackend,
        structured_db: StructuredDBBackend,
        embedder: EmbeddingBackend,
        llm: LLMBackend | None,
        config: PDFProcessorConfig,
    ) -> None:
        self._vector_store = vector_store
        self._structured_db = structured_db
        self._embedder = embedder
        self._llm = llm
        self._config = config
```

Matches the SPEC 11.3 public interface exactly. `llm` is stored for potential future use (MIXED page OCR cleanup) but not used in the initial implementation.

##### process() Method Signature

```python
def process(
    self,
    file_path: str,
    profile: DocumentProfile,
    classification: ClassificationResult,
    ingest_key: str,
    ingest_run_id: str,
    parse_result: ParseStageResult,
    classification_result: ClassificationStageResult,
) -> ProcessingResult:
```

**Rationale:** The SPEC shows 5 params but `ProcessingResult` requires `parse_result` and `classification_result` as non-optional fields. Both TextExtractor and OCRProcessor use this expanded pattern. Follow the established convention.

##### process() Step-by-Step Logic

1. **Initialize** accumulators: `start_time`, `errors: list[str]`, `warnings: list[str]`, `error_details: list[IngestError]`, `written = WrittenArtifacts(vector_collection=config.default_collection)`, `source_uri`.

2. **Open document** with `fitz.open(file_path)` in a context manager for the entire process.

3. **Header/footer detection** (once across full doc):
   ```python
   hf_detector = HeaderFooterDetector(config)
   try:
       header_patterns, footer_patterns = hf_detector.detect(doc)
   except Exception as exc:
       # Recoverable: log warning, continue with empty patterns
       warnings.append(ErrorCode.E_PROCESS_HEADER_FOOTER.value)
       error_details.append(IngestError(..., recoverable=True))
       header_patterns, footer_patterns = [], []
   ```

4. **Heading detection** (once across full doc):
   ```python
   heading_detector = HeadingDetector(config)
   raw_headings = heading_detector.detect(doc)
   ```

5. **Layout analyzer** initialization:
   ```python
   layout_analyzer = LayoutAnalyzer(config)
   ```

6. **Page-level routing loop**: Iterate over `classification.per_page_types` sorted by page number. For each `(page_number, page_type)`:

   - **BLANK** -> `warnings.append(f"{ErrorCode.W_PAGE_SKIPPED_BLANK.value}: page {page_number}")`; skip
   - **TOC** -> `warnings.append(f"{ErrorCode.W_PAGE_SKIPPED_TOC.value}: page {page_number}")`; skip
   - **VECTOR_ONLY** -> `warnings.append(f"{ErrorCode.W_PAGE_SKIPPED_VECTOR_ONLY.value}: page {page_number}")`; skip
   - **TEXT** -> call `_extract_text_page(doc, page_number)` -> returns text string
   - **SCANNED** -> collect page number into `scanned_pages: list[int]` for batch OCR
   - **TABLE_HEAVY** -> collect page number into `table_heavy_pages: list[int]` for batch table extraction; also extract surrounding text via `_extract_text_page()` for any non-table content on the page
   - **FORM** -> call `_extract_form_fields(doc, page_number)` -> returns text string of "Field: Value" pairs; also extract any regular text on the page
   - **MIXED** -> call `_extract_mixed_page(doc, page_number, file_path)` -> returns text string (native text + OCR of image regions)

   For each non-skipped page:
   - Check `profile.pages[page_idx].is_multi_column`; if True, run `layout_analyzer.detect_columns(page)` + `extract_text_blocks(page)` + `layout_analyzer.reorder_blocks()` to get corrected reading order, then assemble text from reordered blocks instead
   - Run `hf_detector.strip(text, page_number, header_patterns, footer_patterns)`
   - Store result in `page_texts: dict[int, str]`

7. **OCR for SCANNED pages** (batch): For each page in `scanned_pages`, call `_ocr_single_page()` sequentially (reusing the module-level function from `ocr_processor.py`). Collect `OCRResult` objects. Store resulting text in `page_texts`.

8. **Table extraction** (batch): If `table_heavy_pages` is non-empty:
   ```python
   table_extractor = TableExtractor(
       config=config,
       structured_db=self._structured_db,
       vector_store=self._vector_store,
       embedder=self._embedder,
   )
   table_result = table_extractor.extract_tables(
       file_path, table_heavy_pages, ingest_key, ingest_run_id,
   )
   ```
   Accumulate `table_result.warnings`, `table_result.errors`, `table_result.table_names`, `table_result.chunks`, `table_result.texts_embedded`, `table_result.embed_duration_seconds`.

9. **Assemble full text**: Sort `page_texts` by page number, concatenate with `"\n"` separators. Compute `page_boundary_list` and `page_offset_map` (same pattern as TextExtractor._concatenate_pages).

10. **Convert headings to character offsets**: Same pattern as TextExtractor._convert_headings_to_offsets.

11. **Language detection**: If `config.enable_language_detection`, detect from first non-empty page text.

12. **Chunk**: `PDFChunker(config).chunk(full_text, headings_with_offsets, page_boundary_list)`.

13. **Build chunk payloads**: For each chunk dict, create `ChunkPayload` with `PDFChunkMetadata`. Use `IngestionMethod.COMPLEX_PROCESSING`. Include `content_type` from chunk dict. Include OCR metadata for chunks from SCANNED pages.

14. **Embed and upsert** text chunks: Same batch embed/upsert pattern as TextExtractor._embed_and_upsert. Track `total_texts_embedded`, `embed_duration`.

15. **Build OCRStageResult**: If any SCANNED pages were processed, build `OCRStageResult` with avg confidence, low-confidence page list.

16. **Build EmbedStageResult**: Combine text chunk embeddings + table extraction embeddings.

17. **Return ProcessingResult**:
    ```python
    return ProcessingResult(
        file_path=file_path,
        ingest_key=ingest_key,
        ingest_run_id=ingest_run_id,
        tenant_id=config.tenant_id,
        parse_result=parse_result,
        classification_result=classification_result,
        ocr_result=ocr_stage_result,  # None if no SCANNED pages
        embed_result=embed_result,
        classification=classification,
        ingestion_method=IngestionMethod.COMPLEX_PROCESSING,
        chunks_created=total_chunks,
        tables_created=len(table_names),
        tables=table_names,
        written=written,
        errors=errors,
        warnings=warnings,
        error_details=error_details,
        processing_time_seconds=time.monotonic() - start_time,
    )
    ```

##### Private Method: `_extract_text_page`

```python
def _extract_text_page(self, doc: fitz.Document, page_number: int) -> str:
    """Extract text from a single TEXT page using pymupdf4llm.

    Args:
        doc: Open fitz document.
        page_number: 1-based page number.

    Returns:
        Extracted markdown text for the page.
    """
```

**Logic:**
1. Call `pymupdf4llm.to_markdown(doc, pages=[page_number - 1])` to extract single page.
2. Return the resulting text string.
3. Wrap in try/except; on failure, fall back to `doc[page_number - 1].get_text()`.

##### Private Method: `_extract_form_fields`

```python
def _extract_form_fields(
    self, doc: fitz.Document, page_number: int
) -> str:
    """Extract AcroForm fields from a FORM page as 'Field: Value' pairs.

    Args:
        doc: Open fitz document.
        page_number: 1-based page number.

    Returns:
        Concatenated 'Field Name: Value' lines, one per widget.
        Empty fields are represented as 'Field Name: (empty)'.
    """
```

**Logic:**
1. Get page: `page = doc[page_number - 1]`
2. Iterate `page.widgets()`:
   - For each widget, read `widget.field_name` and `widget.field_value`
   - Handle `field_value is None` -> use `"(empty)"`
   - For checkbox/radio (field_type == 1): map value to "Yes"/"No" or use raw value
   - Skip signature fields (field_type == 3)
   - Format: `f"{widget.field_name}: {value}"`
3. Also extract any regular text on the page via `page.get_text()` and prepend it
4. Join all lines with `"\n"`
5. Tag extracted text with a header line: `"[Form Fields]"` so the chunker can identify content_type

##### Private Method: `_extract_mixed_page`

```python
def _extract_mixed_page(
    self,
    doc: fitz.Document,
    page_number: int,
    file_path: str,
) -> str:
    """Extract text + OCR image regions from a MIXED page.

    Args:
        doc: Open fitz document.
        page_number: 1-based page number.
        file_path: Path to PDF for _ocr_single_page.

    Returns:
        Combined native text and OCR text from image regions.
    """
```

**Logic:**
1. Extract native text: `page.get_text()` or `pymupdf4llm.to_markdown(doc, pages=[page_number - 1])`
2. Check if page has images: `page.get_images(full=True)`
3. If images exist and `image_coverage_ratio > 0.1` (from profile), OCR the full page via `_ocr_single_page()` and extract only the portions NOT present in native text. **Simpler approach:** If images found, run OCR on the full page, then combine native text with OCR text by appending OCR-only content after native text (with a `"\n\n[OCR from image regions]\n"` separator).
4. Alternative safer approach: just run `_ocr_single_page()` for the page and merge with native text, deduplicating by checking if OCR text is largely already present in native text.
5. On OCR failure, return just the native text and log a warning.

**Design decision:** The simpler approach (native text + full-page OCR, skip duplicate removal) risks text duplication but is more robust. The implementation should: extract native text, run OCR, and if OCR produces significantly more text than native (>20% more words), append the OCR result. Otherwise, use native text only.

##### Private Method: `_apply_layout_reorder`

```python
def _apply_layout_reorder(
    self,
    doc: fitz.Document,
    page_number: int,
    layout_analyzer: LayoutAnalyzer,
) -> str | None:
    """Detect multi-column layout and return reordered text, or None if single-column.

    Args:
        doc: Open fitz document.
        page_number: 1-based page number.
        layout_analyzer: Pre-initialized LayoutAnalyzer.

    Returns:
        Reordered text if multi-column detected, None otherwise.
    """
```

**Logic:**
1. `page = doc[page_number - 1]`
2. `layout = layout_analyzer.detect_columns(page)`
3. If `layout.is_multi_column`:
   - `blocks = extract_text_blocks(page)`
   - `reordered = layout_analyzer.reorder_blocks(blocks, layout)`
   - Return `"\n".join(b.text for b in reordered)`
4. Return `None`

##### Static Method: `_classify_backend_error`

Same pattern as TextExtractor and OCRProcessor:

```python
@staticmethod
def _classify_backend_error(exc: Exception) -> ErrorCode:
    """Map a backend exception to the appropriate error code."""
    msg = str(exc).lower()
    if "timeout" in msg or "timed out" in msg:
        if "embed" in msg:
            return ErrorCode.E_BACKEND_EMBED_TIMEOUT
        return ErrorCode.E_BACKEND_VECTOR_TIMEOUT
    if "connect" in msg or "connection" in msg:
        if "embed" in msg:
            return ErrorCode.E_BACKEND_EMBED_CONNECT
        return ErrorCode.E_BACKEND_VECTOR_CONNECT
    return ErrorCode.E_PROCESS_CHUNK
```

##### Private Method: `_concatenate_pages`

Reuse TextExtractor's pattern (copy as static method or extract to shared utility):

```python
@staticmethod
def _concatenate_pages(
    page_texts: dict[int, str],
) -> tuple[str, list[int], dict[int, int]]:
```

Same implementation as TextExtractor._concatenate_pages.

##### Private Method: `_embed_and_upsert`

Same pattern as TextExtractor._embed_and_upsert but uses `IngestionMethod.COMPLEX_PROCESSING`:

```python
def _embed_and_upsert(
    self,
    chunk_dicts: list[dict],
    source_uri: str,
    ingest_key: str,
    ingest_run_id: str,
    collection: str,
    doc_title: str | None,
    doc_author: str | None,
    doc_date: str | None,
    language: str,
    ocr_results_map: dict[int, OCRResult],
    written: WrittenArtifacts,
    errors: list[str],
    warnings: list[str],
    error_details: list[IngestError],
) -> tuple[EmbedStageResult | None, int]:
```

**Key difference from TextExtractor:** `ocr_results_map` parameter allows setting `ocr_engine`, `ocr_confidence`, `ocr_dpi`, `ocr_preprocessing` on chunks that originated from SCANNED pages. Check if chunk's `page_numbers` overlap with OCR result page numbers.

---

### 2. MODIFY: `packages/ingestkit-pdf/src/ingestkit_pdf/processors/__init__.py`

Add ComplexProcessor to exports:

```python
from ingestkit_pdf.processors.complex_processor import ComplexProcessor

__all__ = [
    "ComplexProcessor",
    "OCRProcessor",
    "TableExtractionResult",
    "TableExtractor",
    "TextExtractor",
]
```

---

### 3. CREATE: `packages/ingestkit-pdf/tests/test_complex_processor.py` (~500 lines)

#### Test Helpers (local to test file)

```python
def _make_parse_result(**overrides) -> ParseStageResult: ...
def _make_classification_result(**overrides) -> ClassificationResult: ...
def _make_classification_stage_result(**overrides) -> ClassificationStageResult: ...
```

Same factory pattern as `test_text_extractor.py`, but using `PDFType.COMPLEX` and `IngestionMethod.COMPLEX_PROCESSING`.

#### Page Routing Logic

| PageType | Extraction Method | Content Added To |
|----------|------------------|-----------------|
| TEXT | `_extract_text_page()` via pymupdf4llm | `page_texts` |
| SCANNED | `_ocr_single_page()` from ocr_processor | `page_texts` + `ocr_results` |
| TABLE_HEAVY | `TableExtractor.extract_tables()` batch | `table_result` (separate chunk path) |
| FORM | `_extract_form_fields()` via page.widgets() | `page_texts` |
| MIXED | `_extract_mixed_page()` native + OCR | `page_texts` + possibly `ocr_results` |
| BLANK | skip, emit W_PAGE_SKIPPED_BLANK | warnings |
| TOC | skip, emit W_PAGE_SKIPPED_TOC | warnings |
| VECTOR_ONLY | skip, emit W_PAGE_SKIPPED_VECTOR_ONLY | warnings |

#### Test Classes and Methods

```python
class TestComplexProcessorPageRouting:
    """R-PC-1: Page-level routing by PageType."""

    def test_text_pages_extracted_via_pymupdf4llm(self): ...
    def test_scanned_pages_use_ocr(self): ...
    def test_table_heavy_pages_delegated_to_table_extractor(self): ...
    def test_form_pages_extract_widgets(self): ...
    def test_mixed_pages_text_plus_ocr(self): ...
    def test_blank_pages_skipped_with_warning(self): ...
    def test_toc_pages_skipped_with_warning(self): ...
    def test_vector_only_pages_skipped_with_warning(self): ...
    def test_all_page_types_in_single_document(self): ...


class TestComplexProcessorFormFields:
    """R-PC-4: AcroForm field extraction."""

    def test_form_field_extraction_name_value_pairs(self): ...
    def test_form_field_empty_value_handled(self): ...
    def test_form_field_checkbox_value(self): ...
    def test_form_field_signature_skipped(self): ...
    def test_form_page_includes_regular_text(self): ...


class TestComplexProcessorMultiColumn:
    """Multi-column layout reordering."""

    def test_multi_column_page_reordered(self): ...
    def test_single_column_page_unchanged(self): ...


class TestComplexProcessorHeaderFooter:
    """Header/footer stripping across all pages."""

    def test_headers_and_footers_stripped(self): ...
    def test_header_footer_detection_failure_is_recoverable(self): ...


class TestComplexProcessorAssembly:
    """ProcessingResult assembly."""

    def test_processing_result_all_fields_populated(self): ...
    def test_empty_document_returns_zero_chunks(self): ...
    def test_ingestion_method_is_complex_processing(self): ...
    def test_tables_created_count_matches(self): ...
    def test_ocr_stage_result_populated_when_scanned_pages(self): ...
    def test_ocr_stage_result_none_when_no_scanned_pages(self): ...
    def test_warnings_accumulated_from_all_sources(self): ...
    def test_error_handling_per_page_recoverable(self): ...
```

#### Mock Strategy

1. **`fitz.open()`**: Patch to return a mock document with mock pages. Each mock page has:
   - `get_text()` -> returns configured text
   - `widgets()` -> returns mock widget iterator for FORM pages
   - `get_images()` -> returns mock image list for MIXED pages
   - `rect.width` -> returns 612.0

2. **`pymupdf4llm.to_markdown()`**: Patch to return configured text per page.

3. **`_ocr_single_page()`**: Patch at `ingestkit_pdf.processors.complex_processor._ocr_single_page` to return mock `OCRResult`.

4. **`TableExtractor.extract_tables()`**: Patch to return a mock `TableExtractionResult`.

5. **Backends**: Use `MockVectorStoreBackend`, `MockEmbeddingBackend`, `MockStructuredDBBackend`, `MockLLMBackend` from `conftest.py`.

6. **Factories**: Use `_make_document_profile`, `_make_page_profile` from `conftest.py`.

#### Key Test: `test_all_page_types_in_single_document`

This is the integration-style unit test that validates the complete routing flow:

- Create a 8-page document profile with one page of each `PageType`
- Create a matching `ClassificationResult` with `per_page_types` mapping each page to its type
- Mock all extraction methods
- Call `process()`
- Assert:
  - Pages 1 (TEXT): pymupdf4llm called with page 0
  - Page 2 (SCANNED): _ocr_single_page called with page 2
  - Page 3 (TABLE_HEAVY): TableExtractor.extract_tables called with [3]
  - Page 4 (FORM): page.widgets() called on page 3 (0-indexed)
  - Page 5 (MIXED): both get_text and _ocr_single_page called
  - Page 6 (BLANK): W_PAGE_SKIPPED_BLANK in warnings
  - Page 7 (TOC): W_PAGE_SKIPPED_TOC in warnings
  - Page 8 (VECTOR_ONLY): W_PAGE_SKIPPED_VECTOR_ONLY in warnings
  - `ingestion_method == IngestionMethod.COMPLEX_PROCESSING`
  - `chunks_created > 0`

---

## Form Field Extraction Detail

PyMuPDF widget API:
- `page.widgets()` returns an iterator of `fitz.Widget` objects
- Each widget has:
  - `field_name: str` -- the form field label
  - `field_value: str | None` -- the current value (None if unfilled)
  - `field_type: int` -- 0=text, 1=button (checkbox/radio), 2=choice, 3=signature
- Implementation formats as: `f"{widget.field_name}: {widget.field_value or '(empty)'}"`
- Button fields (type 1): if `field_value` in ("Yes", "On", "/Yes", "/On") -> "Yes", else "No"
- Signature fields (type 3): skip entirely (not useful for RAG)
- All form field chunks tagged with `content_type=ContentType.FORM_FIELD.value`

---

## ProcessingResult Assembly

The `ProcessingResult` combines results from multiple extraction paths:

| Field | Source |
|-------|--------|
| `chunks_created` | text chunks from _embed_and_upsert + table chunks from TableExtractor |
| `tables_created` | `len(table_result.table_names)` |
| `tables` | `table_result.table_names` |
| `ocr_result` | Built from OCRResults if any SCANNED/MIXED pages were OCR'd |
| `embed_result` | Combined from text embedding + table embedding durations/counts |
| `written.vector_point_ids` | Union of text chunk IDs + table chunk IDs |
| `errors` | Accumulated from all stages |
| `warnings` | Accumulated from all stages |
| `ingestion_method` | `IngestionMethod.COMPLEX_PROCESSING` (always) |

---

## Acceptance Criteria

- [ ] `ComplexProcessor` class created in `processors/complex_processor.py` with SPEC 11.3 constructor signature
- [ ] `process()` accepts expanded 7-param signature matching sibling processors
- [ ] Page routing correctly dispatches all 8 `PageType` values
- [ ] TEXT pages extracted via `pymupdf4llm.to_markdown()` single-page
- [ ] SCANNED pages processed via `_ocr_single_page()` from `ocr_processor.py`
- [ ] TABLE_HEAVY pages batched to `TableExtractor.extract_tables()`
- [ ] FORM pages extract AcroForm widgets as "Field: Value" pairs via `page.widgets()`
- [ ] MIXED pages combine native text + OCR of image regions
- [ ] BLANK/TOC/VECTOR_ONLY pages skipped with correct warning codes
- [ ] Multi-column pages reordered via `LayoutAnalyzer`
- [ ] Header/footer detection + stripping applied across all pages
- [ ] Heading detection runs once on full document
- [ ] All extracted text assembled, chunked, embedded, upserted
- [ ] `ProcessingResult` fully populated with correct `IngestionMethod.COMPLEX_PROCESSING`
- [ ] OCRStageResult populated when SCANNED pages present, None otherwise
- [ ] `ComplexProcessor` exported from `processors/__init__.py`
- [ ] All tests pass with mocked backends (no external services)
- [ ] Error handling: per-page errors are recoverable, backend errors classified correctly

---

## Verification Gates (for PROVE)

```bash
cd packages/ingestkit-pdf && python -m pytest tests/test_complex_processor.py -v
cd packages/ingestkit-pdf && python -m pytest tests/ -v --tb=short  # no regressions
python -c "from ingestkit_pdf.processors import ComplexProcessor; print('import OK')"
```

AGENT_RETURN: .agents/outputs/plan-41-021426.md
