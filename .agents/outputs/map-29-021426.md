---
issue: 29
agent: map
date: 2026-02-14
complexity: medium-high
stack: [python, pydantic, pytest]
title: "Implement Tier 2/3 LLM classifier with outage resilience (llm_classifier.py)"
---

# MAP Artifact: Issue #29 -- PDF LLM Classifier

## Executive Summary

Issue #29 requires implementing `PDFLLMClassifier` in `packages/ingestkit-pdf/src/ingestkit_pdf/llm_classifier.py` along with its test suite. The implementation follows the well-established pattern from the Excel package's `LLMClassifier` (453 lines, 1042 lines of tests) but adapted for PDF-specific models: `DocumentProfile` instead of `FileProfile`, `PDFType` instead of `FileType`, `PageProfile`/`PageType` instead of `SheetProfile`, and `per_page_types` instead of `per_sheet_types`.

The SPEC sections 10.1-10.6 define the requirements precisely. The classifier generates structural summaries from `DocumentProfile` objects (never raw text), sends them to an LLM backend, validates JSON responses against a Pydantic schema, and handles retries/failures gracefully. Outage resilience (degrading to Tier 1) is handled at the **router level** (not in the classifier itself), matching the Excel architecture where the classifier is only responsible for classifying at a requested tier and the router orchestrates escalation.

## Investigation Findings

### 1. Existing Pattern: Excel LLM Classifier

**File:** `/home/jjob/projects/ingestkit/packages/ingestkit-excel/src/ingestkit_excel/llm_classifier.py`

Key architectural decisions to replicate:
- `LLMClassifier` does NOT handle tier escalation -- that is the router's job
- Retry loop: max 2 attempts (1 original + 1 retry)
- On `json.JSONDecodeError`, `TimeoutError`, or generic `Exception` from LLM backend: append correction hint and retry
- On schema validation failure: append schema correction hint and retry
- After 2 failures: return fail-closed result with `confidence=0.0`
- Confidence clamping (not rejection) for out-of-bounds values
- `LLMClassificationResponse` Pydantic model validates response schema
- `_redact()` helper applies `config.redact_patterns`

### 2. PDF-Specific Adaptations Required

#### 2a. Structural Summary (SPEC 10.1)

The Excel version summarizes sheets with row/col counts, merged cells, headers, sample rows (type-only by default). The PDF version must summarize:

| Field | Source in `DocumentProfile` |
|-------|----------------------------|
| File name | `profile.file_path` (basename only) |
| Page count | `profile.page_count` |
| File size | `profile.file_size_bytes` |
| Creator | `profile.metadata.creator` |
| PDF version | `profile.metadata.pdf_version` |
| Page type distribution | `profile.page_type_distribution` (dict[str, int]) |
| Sample page profiles | `profile.pages` (select representative sample) |
| Detected languages | `profile.detected_languages` |
| TOC presence | `profile.has_toc`, `profile.toc_entries` |
| Form fields | `profile.metadata.has_form_fields` |

Sample page profiles should include per-page: `text_length`, `word_count`, `image_count`, `image_coverage_ratio`, `font_count`, `font_names`, `table_count`, `page_type`.

No equivalent to `_infer_cell_type` is needed since there are no sample rows. Instead, the summary format follows the SPEC 10.1 example exactly.

#### 2b. Classification Prompt (SPEC 10.2)

Three types instead of Excel's three:
- `"text_native"` -- Digital PDF with extractable text
- `"scanned"` -- Pages are images requiring OCR
- `"complex"` -- Mix of text, tables, multi-column, forms, mixed scanned/digital

Response schema includes `page_types` (list of `{page, type}` dicts) instead of Excel's `sheet_types` (dict of name to type).

#### 2c. Response Schema Model

```python
class LLMClassificationResponse(BaseModel):
    type: Literal["text_native", "scanned", "complex"]
    confidence: float  # no ge/le -- clamped manually
    reasoning: str = Field(min_length=1)
    page_types: list[dict[str, Any]] | None = None  # [{page: int, type: str}, ...]
```

Note: The SPEC shows `page_types` as a list of `{page, type}` objects, which differs from Excel's `sheet_types` dict. Need a decision on whether to use a strict sub-model for page type entries or validate loosely.

#### 2d. Result Mapping

| Excel | PDF |
|-------|-----|
| `FileType(response.type)` | `PDFType(response.type)` |
| `result.file_type` | `result.pdf_type` |
| `result.per_sheet_types` | `result.per_page_types` |
| `FileType` enum values | `PDFType` enum values |
| `ClassificationResult.signals` | Same |

**Critical:** `ClassificationResult` in PDF models uses `pdf_type: PDFType` (not `file_type`), and `per_page_types: dict[int, PageType]` (not `per_sheet_types: dict[str, FileType]`).

### 3. Model/Type Inventory

#### Models from `ingestkit_pdf.models` (already implemented):
- `PDFType`: `TEXT_NATIVE`, `SCANNED`, `COMPLEX`
- `PageType`: `TEXT`, `SCANNED`, `TABLE_HEAVY`, `FORM`, `MIXED`, `BLANK`, `VECTOR_ONLY`, `TOC`
- `DocumentProfile`: file_path, file_size_bytes, page_count, content_hash, metadata, pages, page_type_distribution, detected_languages, has_toc, toc_entries, overall_quality, security_warnings
- `PageProfile`: page_number, text_length, word_count, image_count, image_coverage_ratio, table_count, font_count, font_names, has_form_fields, is_multi_column, page_type, extraction_quality
- `DocumentMetadata`: title, author, creator, producer, pdf_version, page_count, file_size_bytes, etc.
- `ClassificationResult`: pdf_type, confidence, tier_used, reasoning, per_page_types, signals, degraded
- `ClassificationTier` (from core): `RULE_BASED`, `LLM_BASIC`, `LLM_REASONING`

#### Config from `ingestkit_pdf.config`:
- `classification_model`: `"qwen2.5:7b"` (Tier 2)
- `reasoning_model`: `"deepseek-r1:14b"` (Tier 3)
- `tier2_confidence_threshold`: `0.6`
- `llm_temperature`: `0.1`
- `enable_tier3`: `True`
- `backend_timeout_seconds`: `30.0`
- `log_sample_text`: `False` (PDF equivalent of Excel's `log_sample_data`)
- `log_llm_prompts`: `False`
- `redact_patterns`: `[]`

**Note:** PDF config does NOT have `max_sample_rows`. Need to decide how many sample pages to include in structural summary. Could use a fixed number (e.g., 5) or add a `max_sample_pages` config field.

#### Error codes from `ingestkit_pdf.errors`:
- `E_CLASSIFY_INCONCLUSIVE`
- `E_LLM_TIMEOUT`
- `E_LLM_MALFORMED_JSON`
- `E_LLM_SCHEMA_INVALID`
- `E_LLM_CONFIDENCE_OOB`
- `W_LLM_RETRY`
- `W_LLM_UNAVAILABLE`
- `W_CLASSIFICATION_DEGRADED`

All error codes needed are already defined.

#### Protocol from `ingestkit_core.protocols`:
- `LLMBackend.classify(prompt, model, temperature, timeout) -> dict`
- `LLMBackend.generate(prompt, model, temperature, timeout) -> str`

### 4. Key Differences from Excel Pattern

| Aspect | Excel | PDF |
|--------|-------|-----|
| Input model | `FileProfile` (sheets) | `DocumentProfile` (pages) |
| Type enum | `FileType` (3 values) | `PDFType` (3 values) |
| Sub-unit | Sheets (by name) | Pages (by number) |
| Summary content | Row/col counts, merged cells, headers, sample rows (type-inferred) | Page count, file size, creator, PDF version, page type distribution, sample page profiles, languages, TOC, form fields |
| Response `per_*` field | `sheet_types: dict[str, str]` | `page_types: list[{page, type}]` (per SPEC) |
| Result `per_*` field | `per_sheet_types: dict[str, FileType]` | `per_page_types: dict[int, PageType]` |
| Config sample flag | `log_sample_data` | `log_sample_text` |
| Config sample limit | `max_sample_rows` | None defined (need decision) |
| Result degraded field | N/A | `degraded: bool = False` |
| Logger name | `ingestkit_excel` | `ingestkit_pdf` |

### 5. Outage Handling Scope

Per SPEC 10.6, outage handling is the **router's** responsibility, not the classifier's. The classifier should:
- Raise or propagate exceptions from the LLM backend (after retries exhausted)
- Return fail-closed result (confidence=0.0) when retries are exhausted internally
- NOT set `degraded=True` (that is the router's job)

However, looking at the Excel pattern, the classifier catches all exceptions internally and returns a fail-closed result rather than propagating. The router pattern in SPEC 10.6 shows a try/except around `self._llm_classifier.classify()` which suggests the classifier might also raise.

**Decision needed:** Should the PDF classifier propagate `ConnectionError`/`TimeoutError` to the router (matching SPEC 10.6 router pseudocode), or catch everything internally (matching Excel pattern)? The SPEC 10.6 pseudocode clearly shows the router catching exceptions from the classifier, implying the classifier should let `ConnectionError` propagate rather than swallowing it.

### 6. `page_types` Response Validation

The SPEC 10.2 shows the LLM returning:
```json
"page_types": [{"page": 1, "type": "text"}, {"page": 12, "type": "table_heavy"}]
```

But `ClassificationResult.per_page_types` is `dict[int, PageType]`. The conversion requires:
1. Parse list of `{page, type}` dicts from LLM
2. Validate page numbers exist in profile
3. Validate type values are valid `PageType` enum values
4. Convert to `dict[int, PageType]`

This is more complex than Excel's `sheet_types` validation (simple dict[str, str] to dict[str, FileType]).

## Key Decisions Needed for PLAN

1. **Exception propagation vs. internal absorption:** The Excel classifier catches all exceptions and returns fail-closed. The SPEC 10.6 router pseudocode catches exceptions from the classifier. Should the PDF classifier let `ConnectionError`/`TimeoutError` propagate (for the router to handle) while still handling JSON/schema errors internally? **Recommendation:** Follow SPEC 10.6 -- let connection/timeout errors propagate after retry. Catch JSON/schema errors internally with retry. This matches the router pseudocode and enables proper `degraded=True` handling by the router.

2. **Sample page count for structural summary:** No `max_sample_pages` config exists. Options: (a) hardcode 5 sample pages, (b) add config field. **Recommendation:** Include ALL pages in the summary (since PageProfile is already structural metadata, not raw text). The summary is compact per-page. For very large documents, could cap at ~10 representative pages selected by diversity of `page_type`.

3. **`page_types` response sub-model:** Use a Pydantic sub-model for strict validation or validate manually? **Recommendation:** Use a Pydantic sub-model `PageTypeEntry(BaseModel)` with `page: int` and `type: Literal[...]` for strict validation, matching the schema validation pattern.

4. **`PageType` values in LLM response:** The `PageType` enum has 8 values (`text`, `scanned`, `table_heavy`, `form`, `mixed`, `blank`, `vector_only`, `toc`). Should the LLM be asked to classify into all 8, or a subset? **Recommendation:** Follow SPEC 10.2 which does not restrict -- use all `PageType` values.

5. **`degraded` field handling:** The classifier should NOT set `degraded=True` on its own results. That is the router's job. The fail-closed result should have `degraded=False`. **Recommendation:** Match this understanding.

## Dependency Analysis

### Imports Required (all already exist)
- `ingestkit_pdf.models`: `DocumentProfile`, `PageProfile`, `DocumentMetadata`, `ClassificationResult`, `PDFType`, `PageType`, `ClassificationTier`
- `ingestkit_pdf.config`: `PDFProcessorConfig`
- `ingestkit_pdf.errors`: `ErrorCode`, `IngestError`
- `ingestkit_pdf.protocols`: `LLMBackend`
- `pydantic`: `BaseModel`, `Field`, `ValidationError`
- stdlib: `json`, `logging`, `os`, `re`

### No New Dependencies
All required models, configs, errors, and protocols are already implemented. No new packages needed.

### Downstream Consumers
- `PDFRouter` (issue TBD) will use `PDFLLMClassifier.classify()` in its tier escalation logic
- Tests are self-contained with mock backend

## File Inventory

### Files to Create
| File | Purpose | Estimated Lines |
|------|---------|----------------|
| `packages/ingestkit-pdf/src/ingestkit_pdf/llm_classifier.py` | PDF LLM classifier implementation | ~350-400 |
| `packages/ingestkit-pdf/tests/test_llm_classifier.py` | Full test suite | ~800-900 |

### Files to Read (no modification needed)
| File | Why |
|------|-----|
| `packages/ingestkit-pdf/src/ingestkit_pdf/models.py` | DocumentProfile, ClassificationResult, PDFType, PageType |
| `packages/ingestkit-pdf/src/ingestkit_pdf/config.py` | PDFProcessorConfig fields |
| `packages/ingestkit-pdf/src/ingestkit_pdf/errors.py` | ErrorCode enum values |
| `packages/ingestkit-pdf/src/ingestkit_pdf/protocols.py` | LLMBackend protocol (re-exported from core) |
| `packages/ingestkit-core/src/ingestkit_core/protocols.py` | LLMBackend.classify() signature |
| `packages/ingestkit-core/src/ingestkit_core/models.py` | ClassificationTier enum |
| `packages/ingestkit-excel/src/ingestkit_excel/llm_classifier.py` | Reference pattern |
| `packages/ingestkit-excel/tests/test_llm_classifier.py` | Reference test pattern |

### Files That May Need Minor Updates
| File | Why |
|------|-----|
| `packages/ingestkit-pdf/src/ingestkit_pdf/__init__.py` | Add `PDFLLMClassifier` to public exports |
| `packages/ingestkit-pdf/tests/conftest.py` | Add shared fixtures (MockLLMBackend, DocumentProfile builders) |

## Test Coverage Plan

Test classes to implement (following Excel test pattern):

1. **TestValidResponseParsing** -- valid text_native, scanned, complex responses; page_types conversion; tier_used; signals=None
2. **TestMalformedJsonRetry** -- JSONDecodeError retry, generic exception retry, two failures fail-closed, correction hint in prompt
3. **TestSchemaValidation** -- missing type, invalid type value, missing reasoning, empty reasoning, schema retry then success, two schema failures
4. **TestConfidenceBounds** -- above 1.0 clamped, below 0.0 clamped, exact boundaries, OOB does not trigger retry
5. **TestTimeoutHandling** -- timeout triggers retry, two timeouts fail-closed
6. **TestFailClosed** -- zero confidence, correct tier_used, reasoning mentions failure
7. **TestTierModelSelection** -- tier2 uses classification_model, tier3 uses reasoning_model, rule_based raises ValueError, custom models, temperature, timeout
8. **TestStructuralSummary** -- contains page count/file size/creator/PDF version, page type distribution, sample page profiles, languages, TOC info, form fields info, no raw text by default, filename not full path
9. **TestPromptContent** -- contains all three PDFType values, contains structural summary, requests JSON only
10. **TestPageTypesValidation** -- valid page_types list converted to dict[int, PageType], unknown page numbers logged as warning, invalid page type values caught
11. **TestLLMClassificationResponseModel** -- Pydantic model direct tests

## Risk Assessment

- **Low risk:** Core pattern is well-established from Excel package; models/errors/config are already implemented
- **Medium risk:** `page_types` list-to-dict conversion is more complex than Excel's sheet_types
- **Decision dependency:** Exception propagation strategy affects both classifier and future router implementation
