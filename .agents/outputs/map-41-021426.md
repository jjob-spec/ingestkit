# MAP Artifact: Issue #41 -- Implement Path C Complex Processor

**Issue:** #41 -- Implement ComplexProcessor (`processors/complex_processor.py`)
**Date:** 2026-02-14
**SPEC Section:** 11.3

---

## 1. SPEC Requirements Summary (Section 11.3)

The ComplexProcessor handles Type C (complex/hybrid) PDFs with per-page routing based on `PageType`. Eight steps are specified:

1. **Page-level routing** -- dispatch each page by its `PageType`:
   - `TEXT` -> `TextExtractor` text extraction logic
   - `SCANNED` -> `OCRProcessor` OCR logic
   - `TABLE_HEAVY` -> `TableExtractor` + surrounding text extraction
   - `FORM` -> AcroForm field name+value extraction as `"Field: Value"` pairs
   - `MIXED` -> native text extraction + OCR for image regions
   - `BLANK` -> skip, emit `W_PAGE_SKIPPED_BLANK`
   - `TOC` -> skip, emit `W_PAGE_SKIPPED_TOC`
   - `VECTOR_ONLY` -> skip, emit `W_PAGE_SKIPPED_VECTOR_ONLY`

2. **Table extraction** -- via `TableExtractor.extract_tables()` for `TABLE_HEAVY` pages
3. **Multi-page table stitching** -- already handled inside `TableExtractor._stitch_tables()`
4. **Multi-column handling** -- via `LayoutAnalyzer.detect_columns()` + `reorder_blocks()` for multi-column pages
5. **Form field extraction** -- AcroForm fields via PyMuPDF (`page.widgets()` or `doc.xref_get_key()`)
6. **Header/footer stripping** -- via `HeaderFooterDetector.detect()` + `.strip()` across all pages
7. **Section detection** -- via `HeadingDetector.detect()` for heading hierarchy
8. **Chunk, embed, upsert** -- via `PDFChunker`, `EmbeddingBackend`, `VectorStoreBackend`

**Public interface (from SPEC):**
```python
class ComplexProcessor:
    def __init__(self, vector_store: VectorStoreBackend, structured_db: StructuredDBBackend,
                 embedder: EmbeddingBackend, llm: LLMBackend | None,
                 config: PDFProcessorConfig): ...
    def process(self, file_path: str, profile: DocumentProfile,
                classification: ClassificationResult,
                ingest_key: str, ingest_run_id: str) -> ProcessingResult: ...
```

**IMPORTANT:** The SPEC signature for `process()` shows 5 args but the existing processors (TextExtractor, OCRProcessor) both accept additional `parse_result`, `classification_result`, and `classification` because `ProcessingResult` requires all three as non-optional fields. ComplexProcessor must follow the same expanded pattern.

---

## 2. Existing Processor APIs (Dependencies)

### 2.1 TextExtractor (`processors/text_extractor.py`)
- **Constructor:** `__init__(self, vector_store, embedder, config)`
- **process():** `process(self, file_path, profile, ingest_key, ingest_run_id, parse_result, classification_result, classification) -> ProcessingResult`
- Key internal: `_extract_pages()` returns `dict[int, str]` (page_number -> cleaned text)
- Does NOT accept a `pages` filter parameter -- processes all pages
- ComplexProcessor should NOT call `TextExtractor.process()` directly for individual pages. Instead, replicate the per-page text extraction logic (pymupdf4llm single-page extraction) or use fitz directly

### 2.2 OCRProcessor (`processors/ocr_processor.py`)
- **Constructor:** `__init__(self, vector_store, embedder, llm, config)`
- **process():** `process(self, file_path, profile, pages, ingest_key, ingest_run_id, parse_result, classification_result, classification) -> ProcessingResult`
- **Key:** `pages: list[int] | None` parameter allows targeting specific pages
- Internal `_ocr_pages()` returns `(results: list[OCRResult], errors, warnings)`
- Can reuse `_ocr_single_page()` module-level function directly for per-page OCR
- `OCRResult` has: `page_number, text, confidence, engine_used, dpi, preprocessing_steps, language_detected`

### 2.3 TableExtractor (`processors/table_extractor.py`)
- **Constructor:** `__init__(self, config, structured_db=None, vector_store=None, embedder=None)`
- **extract_tables():** `extract_tables(self, file_path, page_numbers, ingest_key, ingest_run_id) -> TableExtractionResult`
- `TableExtractionResult` has: `tables, chunks, table_names, warnings, errors, texts_embedded, embed_duration_seconds`
- Handles both NL serialization (small tables) and DB routing (large tables)
- Multi-page stitching is internal

### 2.4 LayoutAnalyzer (`utils/layout_analysis.py`)
- **Constructor:** `__init__(self, config)`
- **detect_columns():** `detect_columns(self, page: fitz.Page) -> LayoutResult`
- **reorder_blocks():** `reorder_blocks(self, blocks: list[TextBlock], layout: LayoutResult) -> list[TextBlock]`
- **extract_text_blocks():** module-level function `extract_text_blocks(page: fitz.Page) -> list[TextBlock]`
- `LayoutResult` has: `is_multi_column, column_count, column_boundaries, page_width`
- `TextBlock` has: `x0, y0, x1, y1, text, block_number`

### 2.5 HeaderFooterDetector (`utils/header_footer.py`)
- **Constructor:** `__init__(self, config)`
- **detect():** `detect(self, doc: fitz.Document) -> tuple[list[str], list[str]]` -- returns (header_patterns, footer_patterns)
- **strip():** `strip(self, text, page_number, headers, footers) -> str`

### 2.6 HeadingDetector (`utils/heading_detector.py`)
- **Constructor:** `__init__(self, config)`
- **detect():** `detect(self, doc: fitz.Document) -> list[tuple[int, str, int]]` -- returns (level, title, page_number)

### 2.7 PDFChunker (`utils/chunker.py`)
- **Constructor:** `__init__(self, config)`
- **chunk():** `chunk(self, full_text, headings, page_boundaries) -> list[dict]`
- Each dict has: `text, chunk_index, chunk_hash, page_numbers, heading_path, content_type`

---

## 3. Data Models

### 3.1 Key Enums
- `PageType`: TEXT, SCANNED, TABLE_HEAVY, FORM, MIXED, BLANK, VECTOR_ONLY, TOC
- `PDFType`: TEXT_NATIVE, SCANNED, COMPLEX
- `IngestionMethod`: TEXT_EXTRACTION, OCR_PIPELINE, COMPLEX_PROCESSING
- `ContentType`: NARRATIVE, TABLE, LIST, HEADING, FORM_FIELD, IMAGE_DESCRIPTION, FOOTER, HEADER
- `ErrorCode`: W_PAGE_SKIPPED_BLANK, W_PAGE_SKIPPED_TOC, W_PAGE_SKIPPED_VECTOR_ONLY, W_PAGE_LOW_OCR_CONFIDENCE, E_PROCESS_TABLE_EXTRACT, E_PROCESS_HEADER_FOOTER, E_OCR_FAILED, E_OCR_TIMEOUT, etc.

### 3.2 ProcessingResult Fields (all required)
```python
file_path, ingest_key, ingest_run_id, tenant_id,
parse_result (ParseStageResult), classification_result (ClassificationStageResult),
ocr_result (OCRStageResult | None), embed_result (EmbedStageResult | None),
classification (ClassificationResult), ingestion_method (IngestionMethod),
chunks_created, tables_created, tables (list[str]), written (WrittenArtifacts),
errors (list[str]), warnings (list[str]), error_details (list[IngestError]),
processing_time_seconds
```

### 3.3 ClassificationResult
Has `per_page_types: dict[int, PageType]` -- this is the page-level routing map.

### 3.4 DocumentProfile
Has `pages: list[PageProfile]` where each `PageProfile` has `page_type, page_number, has_form_fields, is_multi_column, table_count, image_count, image_coverage_ratio`, etc.

### 3.5 PDFChunkMetadata (extends BaseChunkMetadata)
Fields: `source_uri, source_format, page_numbers, ingest_run_id, heading_path, content_type, doc_title, doc_author, doc_date, ocr_engine, ocr_confidence, ocr_dpi, ocr_preprocessing, table_index, language`
Inherited from base: `table_name, row_count, columns`

---

## 4. Form Field Extraction via PyMuPDF

PyMuPDF (fitz) provides AcroForm access through:
- `page.widgets()` -- returns iterator of `Widget` objects on a page
- Each `Widget` has: `field_name` (str), `field_value` (str), `field_type` (int)
- Field types: 0=text, 1=button (checkbox/radio), 2=choice, 3=signature
- Extraction: iterate widgets, format as `"Field Name: Value"` pairs
- Tag with `content_type="form_field"`

Alternative: `doc.xref_get_key(xref, "V")` for raw value access, but `page.widgets()` is the standard approach.

---

## 5. Process() Signature Decision

Following the pattern established by TextExtractor and OCRProcessor, the expanded signature should be:

```python
def process(
    self,
    file_path: str,
    profile: DocumentProfile,
    classification: ClassificationResult,
    ingest_key: str,
    ingest_run_id: str,
    parse_result: ParseStageResult,
    classification_result: ClassificationStageResult,
) -> ProcessingResult:
```

Note: The SPEC signature omits `parse_result` and `classification_result` but ProcessingResult requires them. Both existing processors accept them as parameters from the router.

---

## 6. Implementation Architecture

### 6.1 High-Level Flow
```
process()
  |-- Group pages by PageType from classification.per_page_types
  |-- Header/footer detection (once, across full doc)
  |-- Heading detection (once, across full doc)
  |-- For each page:
  |     |-- Route by PageType:
  |     |     TEXT     -> _extract_text_page()     (pymupdf4llm single page)
  |     |     SCANNED  -> _ocr_page()             (reuse _ocr_single_page)
  |     |     TABLE_HEAVY -> collect page numbers  (batch for TableExtractor)
  |     |     FORM     -> _extract_form_fields()   (page.widgets())
  |     |     MIXED    -> _extract_mixed_page()    (text + OCR image regions)
  |     |     BLANK/TOC/VECTOR_ONLY -> skip + warning
  |     |-- Multi-column reorder if needed
  |     |-- Header/footer strip
  |-- Table extraction (batch all TABLE_HEAVY pages via TableExtractor)
  |-- Assemble all page texts in order
  |-- Chunk full text
  |-- Embed and upsert (text chunks + table chunks + form chunks)
  |-- Build ProcessingResult
```

### 6.2 Key Design Decisions
1. **TableExtractor reuse:** Call `TableExtractor.extract_tables()` with all TABLE_HEAVY page numbers at once. It handles multi-page stitching internally.
2. **OCR reuse:** Use `_ocr_single_page()` module-level function from `ocr_processor.py` for SCANNED pages. Do NOT instantiate full OCRProcessor.
3. **Text extraction:** Use `pymupdf4llm.to_markdown()` with `pages=[page_idx]` for individual TEXT pages, or use `fitz` directly for block-level extraction.
4. **Multi-column:** For pages with `is_multi_column=True` in their PageProfile, run `LayoutAnalyzer.detect_columns()` + `reorder_blocks()` on extracted text blocks before assembling page text.
5. **Form fields:** For FORM pages, extract widgets and serialize as `"Field Name: Value\n"` pairs. Also extract any regular text from the page.
6. **MIXED pages:** Extract native text, then identify image regions and OCR them. Use `page.get_images()` to find images, render just those regions.

### 6.3 Error Handling Pattern
- Follow existing processor pattern: accumulate `errors: list[str]`, `warnings: list[str]`, `error_details: list[IngestError]`
- Per-page errors are recoverable (continue processing other pages)
- Backend errors (embed/upsert) use `_classify_backend_error()` static method

---

## 7. Test Requirements (from SPEC)

| Req ID | Description | Test Name |
|--------|-------------|-----------|
| R-PC-1 | Path C page-level routing | `test_page_routing` |
| R-PC-4 | Form field extraction | `test_form_fields` |

### 7.1 Additional Test Cases Needed
- `test_skip_blank_toc_vector_only` -- verifies skip + warning emission for BLANK/TOC/VECTOR_ONLY pages
- `test_table_heavy_pages_delegated` -- verifies TABLE_HEAVY pages routed to TableExtractor
- `test_scanned_pages_ocr` -- verifies SCANNED pages use OCR
- `test_mixed_pages` -- verifies MIXED pages get text + OCR
- `test_multi_column_reorder` -- verifies multi-column text reordering
- `test_header_footer_stripping` -- verifies h/f detection and stripping
- `test_processing_result_assembled` -- verifies all ProcessingResult fields populated
- `test_empty_document` -- all pages skipped, returns 0 chunks

### 7.2 Mock Strategy
- Mock `fitz.open()` to return mock document with mock pages
- Mock `pymupdf4llm.to_markdown()` for text extraction
- Mock `page.widgets()` for form field extraction
- Mock `pdfplumber.open()` (done inside TableExtractor mock or patch)
- Use `MockVectorStoreBackend`, `MockEmbeddingBackend`, `MockStructuredDBBackend`, `MockLLMBackend` from `conftest.py`
- Use `_make_document_profile`, `_make_page_profile` factories from conftest

---

## 8. Files to Create/Modify

### 8.1 Create
- `packages/ingestkit-pdf/src/ingestkit_pdf/processors/complex_processor.py`
- `packages/ingestkit-pdf/tests/test_complex_processor.py`

### 8.2 Modify
- `packages/ingestkit-pdf/src/ingestkit_pdf/processors/__init__.py` -- add ComplexProcessor export

---

## 9. Dependencies Status

| Dependency | File | Status |
|-----------|------|--------|
| TextExtractor (#38) | `processors/text_extractor.py` | Implemented |
| OCRProcessor (#39) | `processors/ocr_processor.py` | Implemented |
| TableExtractor (#40) | `processors/table_extractor.py` | Implemented |
| HeaderFooterDetector (#30) | `utils/header_footer.py` | Implemented |
| HeadingDetector (#31) | `utils/heading_detector.py` | Implemented |
| PDFChunker (#32) | `utils/chunker.py` | Implemented |
| LayoutAnalyzer (#37) | `utils/layout_analysis.py` | Implemented |

All dependencies are implemented and available.

---

## 10. Risk Areas

1. **MIXED page handling:** The SPEC says "extract text natively, OCR image regions." Identifying and rendering just image regions from a page requires `page.get_images()` + `page.get_image_bbox()` and rendering sub-regions. This is more complex than full-page OCR.

2. **Process signature mismatch:** SPEC shows 5-param signature but ProcessingResult requires `parse_result` and `classification_result`. Must use the expanded 7-param pattern established by sibling processors.

3. **Per-page text extraction:** TextExtractor processes all pages at once via `pymupdf4llm.to_markdown(page_chunks=True)`. For ComplexProcessor, we need per-page control. Use `pymupdf4llm.to_markdown(doc, pages=[page_idx])` for individual pages or use fitz block-level extraction directly.

4. **Form field value types:** PyMuPDF `widget.field_value` can be None for unfilled fields. Must handle None values gracefully.

5. **OCR for MIXED pages:** Need to render only image regions, not the full page. Alternative: render full page and OCR, then merge with native text. The simpler approach (full page OCR + native text merge) may produce duplicate text. Prefer: extract native text blocks, identify non-text (image) bounding boxes, render those regions, OCR them, then combine.
