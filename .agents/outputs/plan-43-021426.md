---
issue: 43
agent: PLAN
date: 2026-02-14
complexity: COMPLEX
stack: backend
map_artifact: .agents/outputs/map-43-021426.md
---

# PLAN: Issue #43 — Test Infrastructure, Mock Backends, and PDF Fixtures

## Executive Summary

Enhance the existing `conftest.py` mock backends with configurable error injection (timeout, connection errors), add five programmatic PDF fixtures using reportlab/PyMuPDF, and create `test_utils.py` for test infrastructure validation. All four mock backends already exist and satisfy their protocol signatures; this plan adds error simulation capabilities and assertion helpers without breaking existing consumers. PDF fixtures must be generated at test time using reportlab (no binary files committed).

---

## 1. Files to Modify/Create

| File | Action | Lines (est.) |
|------|--------|-------------|
| `packages/ingestkit-pdf/tests/conftest.py` | **Modify** | +200 |
| `packages/ingestkit-pdf/tests/test_utils.py` | **Create** | ~150 |

---

## 2. Detailed Implementation Steps

### 2.1 Enhance Mock Backends in `conftest.py`

**CRITICAL**: Do NOT rename or restructure existing classes. Three test files directly import: `MockLLMBackend`, `MockVectorStoreBackend`, `MockEmbeddingBackend`, `_make_document_profile`, `_make_page_profile`, `_make_extraction_quality`, `_valid_response`. All existing method signatures and class names must remain unchanged.

#### 2.1.1 MockLLMBackend Enhancements

**Current state** (lines 29-86): Single `_responses` queue shared between `classify()` and `generate()`. Pops from front. Raises `RuntimeError` when empty. Already supports `Exception` objects in the queue.

**Add:**

1. **Sentinel constants** at module level (above the class):
   ```python
   _SENTINEL_TIMEOUT = "__TIMEOUT__"
   _SENTINEL_CONNECTION_ERROR = "__CONNECTION_ERROR__"
   _SENTINEL_MALFORMED_JSON = "__MALFORMED_JSON__"
   ```

2. **Sentinel handling** in `classify()` — after `response = self._responses.pop(0)`, before the existing `isinstance(response, Exception)` check:
   ```python
   if response == _SENTINEL_TIMEOUT:
       raise TimeoutError("MockLLMBackend simulated timeout")
   if response == _SENTINEL_CONNECTION_ERROR:
       raise ConnectionError("MockLLMBackend simulated connection error")
   if response == _SENTINEL_MALFORMED_JSON:
       return {"raw": "<<<not json>>>"}
   ```

3. **Same sentinel handling** in `generate()` (except `_SENTINEL_MALFORMED_JSON` is not applicable for string returns; skip it there).

4. **Convenience enqueue methods** (matching Excel's `MockLLM` pattern):
   ```python
   def enqueue_classify(self, *responses: dict | str | Exception) -> None:
       self._responses.extend(responses)

   def enqueue_generate(self, *responses: dict | str | Exception) -> None:
       self._responses.extend(responses)

   def enqueue_timeout(self) -> None:
       self._responses.append(_SENTINEL_TIMEOUT)

   def enqueue_connection_error(self) -> None:
       self._responses.append(_SENTINEL_CONNECTION_ERROR)
   ```

5. **Assertion helpers:**
   ```python
   @property
   def call_count(self) -> int:
       return len(self.calls)

   def assert_called_with_model(self, model: str) -> None:
       assert any(c["model"] == model for c in self.calls), (
           f"Expected call with model={model!r}, got: {[c['model'] for c in self.calls]}"
       )
   ```

**Backward compatibility**: The existing `classify()` and `generate()` methods already handle `Exception` objects via `isinstance(response, Exception)`. The sentinel strings are checked BEFORE that check, so existing tests that pass `Exception` instances continue to work. `enqueue_classify`/`enqueue_generate` add to the same `_responses` queue.

#### 2.1.2 MockVectorStoreBackend Enhancements

**Current state** (lines 94-115): Tracks operations in lists. No error injection.

**Add:**

1. **Error queue field** in `__init__`:
   ```python
   self._errors: dict[str, Exception | None] = {}
   ```

2. **Error injection methods:**
   ```python
   def fail_next_upsert(self, error: Exception | None = None) -> None:
       self._errors["upsert"] = error or ConnectionError("MockVectorStore simulated error")

   def fail_next_ensure(self, error: Exception | None = None) -> None:
       self._errors["ensure"] = error or ConnectionError("MockVectorStore simulated error")
   ```

3. **Error trigger** at the start of `upsert_chunks()` and `ensure_collection()`:
   ```python
   if "upsert" in self._errors:
       err = self._errors.pop("upsert")
       raise err
   ```

4. **Assertion helper:**
   ```python
   @property
   def total_chunks_upserted(self) -> int:
       return sum(len(chunks) for _, chunks in self.upserted)
   ```

#### 2.1.3 MockEmbeddingBackend Enhancements

**Current state** (lines 123-135): Returns constant `[0.1] * dim` vectors.

**Add:**

1. **Error queue field** in `__init__`:
   ```python
   self._error_on_next: Exception | None = None
   ```

2. **Error injection method:**
   ```python
   def fail_next_embed(self, error: Exception | None = None) -> None:
       self._error_on_next = error or TimeoutError("MockEmbeddingBackend simulated timeout")
   ```

3. **Error trigger** at start of `embed()`:
   ```python
   if self._error_on_next is not None:
       err = self._error_on_next
       self._error_on_next = None
       raise err
   ```

4. **Assertion helper:**
   ```python
   @property
   def total_texts_embedded(self) -> int:
       return sum(len(batch) for batch in self.calls)
   ```

#### 2.1.4 MockStructuredDBBackend Enhancements

**Current state** (lines 143-167): In-memory dict of tables.

**Add:**

1. **Error queue field** in `__init__`:
   ```python
   self._error_on_next: Exception | None = None
   ```

2. **Error injection method:**
   ```python
   def fail_next_create(self, error: Exception | None = None) -> None:
       self._error_on_next = error or ConnectionError("MockStructuredDBBackend simulated error")
   ```

3. **Error trigger** at start of `create_table_from_dataframe()`:
   ```python
   if self._error_on_next is not None:
       err = self._error_on_next
       self._error_on_next = None
       raise err
   ```

---

### 2.2 Add PDF Fixtures to `conftest.py`

All five fixtures use `tmp_path` (function-scoped per SPEC). Add these after the existing `Pytest Fixtures` section. Add required imports at top of file:

```python
import io
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
import fitz  # PyMuPDF
from reportlab.lib.pagesizes import letter
from reportlab.lib.units import inch
from reportlab.pdfgen import canvas
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Frame, PageTemplate
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib import colors
```

#### 2.2.1 `text_native_pdf(tmp_path)` fixture

**Purpose**: Multi-page PDF with headings, paragraphs, and page numbers. Clean digital PDF with extractable text.

**Implementation strategy**: Use `reportlab.pdfgen.canvas.Canvas` directly:
- 3 pages
- Page 1: Heading ("Chapter 1: Introduction") in Helvetica-Bold 18pt, followed by 2-3 body paragraphs in Helvetica 11pt
- Page 2: Heading ("Chapter 2: Methods") + body text
- Page 3: Heading ("Chapter 3: Results") + body text
- Each page has a page number footer: "Page N of 3"
- Returns `Path` to the generated file

**Key details**:
- Use `c.setFont("Helvetica-Bold", 18)` for headings
- Use `c.setFont("Helvetica", 11)` for body
- Use `c.drawString(100, 50, f"Page {i} of 3")` for page numbers
- Place body text starting at y=700, wrapping manually every ~80 chars or using `drawString` at decremented y positions
- Use `c.showPage()` between pages

#### 2.2.2 `scanned_pdf(tmp_path)` fixture

**Purpose**: PDF where pages contain only raster images (no text layer). Simulates scanned documents.

**Implementation strategy**:
1. Use PIL to create images with rendered text:
   ```python
   img = Image.new("RGB", (int(8.5*150), int(11*150)), "white")  # 150 DPI
   draw = ImageDraw.Draw(img)
   draw.text((100, 100), "This is a scanned page", fill="black")
   ```
2. Save images to BytesIO as PNG
3. Use reportlab `canvas.drawImage()` with `ImageReader` to embed each image as a full-page image
4. Result: PDF pages that are images only, no extractable text

**Key details**:
- 2 pages minimum
- Each image has different text content to test per-page OCR
- Use `ImageReader` from `reportlab.lib.utils` for in-memory image loading
- Page 1: "Scanned Document - Page 1" with some body text drawn as image
- Page 2: "Scanned Document - Page 2" with different body text

#### 2.2.3 `complex_pdf(tmp_path)` fixture

**Purpose**: PDF with tables, multi-column layout, and mixed content. Exercises table extraction and layout analysis.

**Implementation strategy**: Use `reportlab.platypus` for structured layout:
1. Page 1: Title heading + a data table (5 cols x 8 rows) using `platypus.Table`
2. Page 2: Two-column text section (use `Frame` objects in `PageTemplate`) + a smaller summary table
3. Headers/footers via `onPage` callback

**Key details**:
- Table data: Employee-like data (ID, Name, Department, Salary, Start Date)
- Table styled with `TableStyle` (header row bold, grid lines, alternating row colors)
- Two-column section uses two `Frame` objects side by side
- Footer: "Confidential - Page N" via `canvas.drawString` in `onPage`

#### 2.2.4 `encrypted_pdf(tmp_path)` fixture

**Purpose**: Password-protected PDF for testing encryption detection.

**Implementation strategy**: Reuse the proven pattern from `test_security.py` (lines 244-264):
1. Create a simple PDF with reportlab or PyMuPDF (`fitz`)
2. Encrypt using `fitz.open()` + `doc.save(encryption=fitz.PDF_ENCRYPT_AES_256, user_pw="testpass", owner_pw="ownerpass")`

**Key details**:
- User password: `"testpass123"` (requires password to open)
- Owner password: `"ownerpass456"`
- Permissions: print + accessibility
- Returns a `tuple[Path, str]` or just `Path` with password stored as an attribute or alongside — SPEC shows `encrypted_pdf(tmp_path) -> Path`, so return `Path` only. Include a module-level constant `ENCRYPTED_PDF_PASSWORD = "testpass123"` for test use.

#### 2.2.5 `garbled_pdf(tmp_path)` fixture

**Purpose**: PDF with text that appears garbled when extracted, simulating CIDFont encoding issues.

**Implementation strategy**:
1. Use reportlab to create a PDF with non-printable/garbled characters
2. Write a mix of: Unicode replacement characters (U+FFFD), zero-width spaces, control characters, and random byte sequences mapped to text positions
3. The key metric: when extracted via pdfminer/pymupdf, the `printable_ratio` should be LOW (< 0.5)

**Key details**:
- Create text strings with high proportion of non-printable characters: `"\ufffd\x00\x01\x02 garbled \ufffd\ufffd text \x03\x04"`
- Mix with some actual printable text so the PDF is structurally valid
- 1-2 pages
- This exercises the quality scoring path (`ExtractionQuality.printable_ratio`) and `E_PARSE_GARBLED` detection

---

### 2.3 Create `test_utils.py`

**File**: `packages/ingestkit-pdf/tests/test_utils.py`

**Purpose**: Validate the test infrastructure itself (mock backends and PDF fixtures). This ensures the test fixtures produce valid, well-formed PDFs and that mock backends behave correctly with error injection.

**Test classes and methods:**

#### 2.3.1 `TestMockLLMBackend`
- `test_classify_returns_enqueued_response`: Enqueue a dict, call `classify()`, verify returned
- `test_generate_returns_enqueued_response`: Enqueue a string, call `generate()`, verify returned
- `test_classify_raises_on_empty_queue`: Verify `RuntimeError` when no responses
- `test_timeout_sentinel_raises_timeout_error`: Enqueue `_SENTINEL_TIMEOUT`, verify `TimeoutError`
- `test_connection_error_sentinel_raises`: Enqueue `_SENTINEL_CONNECTION_ERROR`, verify `ConnectionError`
- `test_malformed_json_sentinel_returns_garbled_dict`: Verify returns `{"raw": "<<<not json>>>"}`
- `test_enqueue_timeout_convenience`: Use `enqueue_timeout()`, verify `TimeoutError`
- `test_enqueue_connection_error_convenience`: Use `enqueue_connection_error()`, verify `ConnectionError`
- `test_calls_tracked`: Multiple calls, verify `calls` list and `call_count`
- `test_assert_called_with_model`: Verify assertion helper works

#### 2.3.2 `TestMockVectorStoreBackend`
- `test_upsert_and_tracking`: Upsert chunks, verify tracking lists
- `test_ensure_collection_tracked`: Call `ensure_collection`, verify tracking
- `test_delete_by_ids_tracked`: Call `delete_by_ids`, verify tracking
- `test_fail_next_upsert`: Set error, verify raises on next `upsert_chunks()`
- `test_error_clears_after_raise`: Verify error only fires once
- `test_total_chunks_upserted_property`: Verify computed property

#### 2.3.3 `TestMockEmbeddingBackend`
- `test_returns_correct_dimension_vectors`: Verify vector length matches `dim`
- `test_calls_tracked`: Multiple calls, verify tracking
- `test_fail_next_embed`: Set error, verify raises
- `test_total_texts_embedded_property`: Verify computed property

#### 2.3.4 `TestMockStructuredDBBackend`
- `test_create_and_exists`: Create table, verify `table_exists()`
- `test_drop_table`: Create then drop, verify removed
- `test_get_table_schema`: Verify schema dict from a DataFrame
- `test_get_connection_uri`: Verify returns `"sqlite:///:memory:"`
- `test_fail_next_create`: Set error, verify raises on `create_table_from_dataframe()`

#### 2.3.5 `TestPDFFixtures`
- `test_text_native_pdf_is_valid(text_native_pdf)`: Open with fitz, verify 3 pages, text extractable, page numbers present
- `test_text_native_pdf_has_headings(text_native_pdf)`: Extract text, verify heading strings present
- `test_scanned_pdf_has_no_text(scanned_pdf)`: Open with fitz, verify pages have images but minimal/no extractable text
- `test_scanned_pdf_page_count(scanned_pdf)`: Verify 2+ pages
- `test_complex_pdf_has_tables(complex_pdf)`: Open with pdfplumber, verify table detection
- `test_complex_pdf_is_multi_page(complex_pdf)`: Verify 2+ pages
- `test_encrypted_pdf_requires_password(encrypted_pdf)`: Open with fitz, verify `doc.needs_pass` is True
- `test_garbled_pdf_low_printable_ratio(garbled_pdf)`: Extract text with fitz, compute printable ratio, verify < 0.5

All tests marked with `@pytest.mark.unit`.

---

## 3. Implementation Order

1. **Step 1**: Add imports to `conftest.py` (reportlab, PIL, fitz, pathlib)
2. **Step 2**: Add sentinel constants at module level
3. **Step 3**: Enhance `MockLLMBackend` (sentinels + enqueue methods + helpers)
4. **Step 4**: Enhance `MockVectorStoreBackend` (error injection + helpers)
5. **Step 5**: Enhance `MockEmbeddingBackend` (error injection + helpers)
6. **Step 6**: Enhance `MockStructuredDBBackend` (error injection + helpers)
7. **Step 7**: Add `ENCRYPTED_PDF_PASSWORD` constant
8. **Step 8**: Add `text_native_pdf` fixture
9. **Step 9**: Add `scanned_pdf` fixture
10. **Step 10**: Add `complex_pdf` fixture
11. **Step 11**: Add `encrypted_pdf` fixture
12. **Step 12**: Add `garbled_pdf` fixture
13. **Step 13**: Create `test_utils.py` with all test classes
14. **Step 14**: Run `ruff check .` and fix any issues
15. **Step 15**: Run `pytest tests/test_utils.py -v` to verify all tests pass

---

## 4. Acceptance Criteria Checklist

From the GitHub issue:

- [ ] All four mock backends implement their respective protocols
- [ ] MockLLMBackend can be configured to raise ConnectionError/TimeoutError
- [ ] All test PDF fixtures generate valid PDFs at test time
- [ ] No binary PDF files committed to the repo
- [ ] Pytest markers correctly defined and usable
- [ ] Text-native fixture produces a clean digital PDF
- [ ] Scanned fixture produces image-only pages
- [ ] Complex fixture includes tables and mixed content
- [ ] `pytest tests/ -q --collect-only` shows fixtures available
- [ ] `ruff check .` passes

---

## 5. Verification Gates for PROVE

```bash
# Lint
cd packages/ingestkit-pdf && ruff check .

# Collect test fixtures (verify visibility)
cd packages/ingestkit-pdf && pytest tests/ -q --collect-only 2>&1 | grep -E "(text_native_pdf|scanned_pdf|complex_pdf|encrypted_pdf|garbled_pdf)"

# Run test_utils.py
cd packages/ingestkit-pdf && pytest tests/test_utils.py -v -m unit

# Run full test suite (no regressions)
cd packages/ingestkit-pdf && pytest tests/ -v -m unit

# Verify no binary PDF files
find packages/ingestkit-pdf -name "*.pdf" -not -path "*/tmp*" | wc -l  # should be 0
```

---

## 6. Risks and Mitigations

| Risk | Mitigation |
|------|-----------|
| Scanned PDF fixture: PIL `ImageFont.truetype` may not find system fonts | Use `ImageFont.load_default()` as fallback; the text just needs to render as an image |
| complex_pdf with platypus `Frame` multi-column: Layout may be fragile | Keep layout simple; 2 frames side by side, basic paragraph flowables. If platypus is too complex, fall back to manual canvas positioning |
| garbled_pdf: Characters may get stripped by reportlab | Test that the generated PDF actually has low printable ratio after generation; if reportlab sanitizes chars, use fitz `TextWriter` to write raw bytes instead |
| Existing test imports break | No renames, no signature changes to existing methods. All additions are new methods/properties |

---

## 7. Scope Boundaries

**In scope**: Mock backend enhancements, 5 PDF fixtures, test_utils.py
**Out of scope**: New pytest markers (already exist in pyproject.toml), binary fixtures, changes to `models.py`/`errors.py`/`config.py`, test files for other modules

AGENT_RETURN: .agents/outputs/plan-43-021426.md
