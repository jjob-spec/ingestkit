---
issue: 39
agent: map
date: 2026-02-14
complexity: COMPLEX
stack: [python, pydantic, pytest, ocr, multiprocessing]
title: "Implement Path B OCR Processor (processors/ocr_processor.py)"
---

# MAP Artifact: Issue #39 -- Path B OCR Processor

## Executive Summary

Issue #39 requires implementing `OCRProcessor` in `packages/ingestkit-pdf/src/ingestkit_pdf/processors/ocr_processor.py` with its test suite. This is the scanned-PDF processing path: render pages to images, preprocess, detect language, run OCR in parallel via `ProcessPoolExecutor`, postprocess text, optionally clean with LLM, flag low-confidence pages, then feed cleaned text through heading detection, chunking, embedding, and vector upsert. All utility modules (PageRenderer, OCR engines, ocr_postprocess, language detection, heading detector, chunker, header/footer detector) are already implemented and tested. The processor orchestrates these utilities into a coherent pipeline following the pattern established by the Excel `StructuredDBProcessor`.

## Investigation Findings

### 1. SPEC Requirements (Section 11.2)

**Input:** `DocumentProfile` + classification confirming Type B (scanned) or pages flagged for OCR fallback.

**Steps (9 total):**
1. Render each page to high-DPI image (default 300) via `PageRenderer.render_page()`
2. Preprocess images via `PageRenderer.preprocess()` (deskew, denoise, binarize, contrast)
3. Detect language per page if `enable_language_detection=True` via `detect_language()`
4. Run OCR via configured engine (from `create_ocr_engine()`)
5. Collect per-page `OCRResult` with confidence scores
6. Postprocess OCR text via `postprocess_ocr_text()`
7. Optionally clean via LLM if `enable_ocr_cleanup=True` using `config.ocr_cleanup_model`
8. Flag low-confidence pages (< `config.ocr_confidence_threshold`) with `W_PAGE_LOW_OCR_CONFIDENCE`
9. Route cleaned text through: heading detection -> chunking -> embedding -> upsert

**Parallelism:** Pages OCR'd in parallel via `ProcessPoolExecutor` with `config.ocr_max_workers`. Each worker creates own OCR engine instance. Per-page timeout: `config.ocr_per_page_timeout_seconds`.

**Public Interface:**
```python
class OCRProcessor:
    def __init__(self, vector_store: VectorStoreBackend, embedder: EmbeddingBackend,
                 llm: LLMBackend | None, config: PDFProcessorConfig): ...
    def process(self, file_path: str, profile: DocumentProfile,
                pages: list[int] | None, ingest_key: str, ingest_run_id: str) -> ProcessingResult: ...
```

### 2. Existing Utility Inventory (All Implemented)

| Utility | File | Key API | Status |
|---------|------|---------|--------|
| PageRenderer | `utils/page_renderer.py` | `render_page(page) -> Image`, `preprocess(image) -> Image` | Done |
| OCR Engines | `utils/ocr_engines.py` | `create_ocr_engine(config) -> (engine, warnings)`, `engine.recognize(image, lang) -> OCRPageResult` | Done |
| OCR Postprocess | `utils/ocr_postprocess.py` | `postprocess_ocr_text(text) -> str` | Done |
| Language Detection | `utils/language.py` | `detect_language(text, default_language=) -> (lang, conf)`, `map_language_to_ocr(lang, engine) -> str` | Done |
| Heading Detector | `utils/heading_detector.py` | `HeadingDetector(config).detect(doc) -> [(level, title, page)]`, `.get_heading_path(page, y) -> [str]` | Done |
| Chunker | `utils/chunker.py` | `PDFChunker(config).chunk(text, headings, page_boundaries) -> [dict]` | Done |
| Header/Footer | `utils/header_footer.py` | `HeaderFooterDetector(config).detect(doc) -> (headers, footers)`, `.strip(text, page, headers, footers) -> str` | Done |

### 3. Model Inventory (All Implemented)

**From `ingestkit_pdf.models`:**
- `OCRResult`: page_number, text, confidence, engine_used (OCREngine), dpi, preprocessing_steps, language_detected
- `OCRStageResult`: pages_ocrd, engine_used, avg_confidence, low_confidence_pages, ocr_duration_seconds, engine_fallback_used
- `ProcessingResult`: file_path, ingest_key, ingest_run_id, tenant_id, parse_result, classification_result, ocr_result, embed_result, classification, ingestion_method, chunks_created, tables_created, tables, written, errors, warnings, error_details, processing_time_seconds
- `PDFChunkMetadata`: extends BaseChunkMetadata with page_numbers, heading_path, content_type, doc_title, doc_author, doc_date, ocr_engine, ocr_confidence, ocr_dpi, ocr_preprocessing, table_index, language
- `IngestionMethod.OCR_PIPELINE` = `"ocr_pipeline"`
- `OCREngine.TESSERACT`, `OCREngine.PADDLEOCR`

**From `ingestkit_core.models`:**
- `ChunkPayload`: id, text, vector, metadata (BaseChunkMetadata)
- `WrittenArtifacts`: vector_point_ids, vector_collection, db_table_names
- `EmbedStageResult`: texts_embedded, embedding_dimension, embed_duration_seconds

### 4. Config Fields Relevant to OCR (from `config.py`)

| Field | Default | Used In |
|-------|---------|---------|
| `ocr_engine` | `OCREngine.TESSERACT` | Engine selection |
| `ocr_dpi` | `300` | PageRenderer, metadata |
| `ocr_language` | `"en"` | Language fallback |
| `ocr_confidence_threshold` | `0.7` | Low-confidence flagging |
| `ocr_preprocessing_steps` | `["deskew"]` | PageRenderer, metadata |
| `ocr_max_workers` | `4` | ProcessPoolExecutor |
| `ocr_per_page_timeout_seconds` | `60` | Per-page timeout |
| `enable_ocr_cleanup` | `False` | LLM cleanup gate |
| `ocr_cleanup_model` | `"qwen2.5:7b"` | LLM cleanup model |
| `enable_language_detection` | `True` | Language detection gate |
| `default_language` | `"en"` | Fallback language |
| `embedding_batch_size` | `64` | Batch embedding |
| `backend_timeout_seconds` | `30.0` | Backend calls |
| `default_collection` | `"helpdesk"` | Vector collection |
| `chunk_size_tokens` | `512` | Chunking |
| `chunk_overlap_tokens` | `50` | Chunking |
| `log_ocr_output` | `False` | PII-safe logging |
| `log_sample_text` | `False` | PII-safe logging |
| `parser_version` | `"ingestkit_pdf:1.0.0"` | Metadata |
| `tenant_id` | `None` | Metadata propagation |

### 5. Error Codes Relevant to OCR (from `errors.py`)

| Code | Type | Usage |
|------|------|-------|
| `E_OCR_ENGINE_UNAVAILABLE` | Error | No OCR engine available |
| `E_OCR_TIMEOUT` | Error | Per-page OCR timeout |
| `E_OCR_FAILED` | Error | General OCR failure |
| `W_PAGE_LOW_OCR_CONFIDENCE` | Warning | Page confidence < threshold |
| `W_OCR_ENGINE_FALLBACK` | Warning | PaddleOCR -> Tesseract fallback |
| `W_PAGE_SKIPPED_BLANK` | Warning | Blank page skipped |
| `W_PAGE_SKIPPED_TOC` | Warning | TOC page skipped |
| `W_PAGE_SKIPPED_VECTOR_ONLY` | Warning | Vector-only page skipped |
| `E_BACKEND_VECTOR_TIMEOUT` | Error | Vector store timeout |
| `E_BACKEND_EMBED_TIMEOUT` | Error | Embedding timeout |
| `E_PROCESS_CHUNK` | Error | Chunking failure |

### 6. Protocol Dependencies (from `ingestkit_core.protocols`)

- `VectorStoreBackend`: `upsert_chunks()`, `ensure_collection()`, `create_payload_index()`, `delete_by_ids()`
- `EmbeddingBackend`: `embed(texts, timeout) -> list[list[float]]`, `dimension() -> int`
- `LLMBackend`: `generate(prompt, model, temperature, timeout) -> str` (for OCR cleanup)

**Note:** OCR cleanup uses `LLMBackend.generate()` (not `classify()`), since it produces free-text cleanup, not JSON classification.

### 7. Reference Pattern: Excel StructuredDBProcessor

Key patterns to replicate from `packages/ingestkit-excel/src/ingestkit_excel/processors/structured_db.py`:

- Constructor takes backends + config via DI
- `process()` returns fully-assembled `ProcessingResult`
- `time.monotonic()` for duration measurement
- Per-unit error handling (per-sheet in Excel, per-page in PDF): catch exceptions, record error codes, continue
- `WrittenArtifacts` tracks vector_point_ids and vector_collection
- `EmbedStageResult` assembled at end if any embeddings were done
- Chunk IDs generated via `uuid.uuid5(NAMESPACE_URL, f"{ingest_key}:{chunk_hash}")`
- Chunk hashes via `hashlib.sha256(text.encode()).hexdigest()`
- Batch embedding with `config.embedding_batch_size`
- `ensure_collection()` called before upserting
- Error classification helper method for backend exceptions

### 8. Parallelism Design Considerations

**ProcessPoolExecutor constraints:**
- Each worker needs its own OCR engine instance (PaddleOCR shared instance issue per SPEC)
- `fitz.Page` objects are NOT picklable -- must pass file_path + page_number to workers
- Workers must: open PDF, render page, preprocess, OCR, return `OCRResult`
- Per-page timeout via `concurrent.futures.as_completed()` with timeout per future
- PIL Image objects are large in memory -- workers should render + OCR internally, not return images

**Serialization boundary:** The worker function must be a module-level function (not a method) for `ProcessPoolExecutor` pickling. It receives serializable arguments (file_path, page_number, config fields, engine name, language) and returns a serializable `OCRResult` or error tuple.

**Alternative approach:** For unit testability without actual multiprocessing, the processor could use an abstraction that defaults to `ProcessPoolExecutor` but can be swapped to sequential execution in tests. Or simply test the per-page logic independently and test the orchestration with mocked futures.

### 9. Downstream Pipeline After OCR (Step 9)

After OCR produces cleaned text per page, the processor must:
1. Open the PDF with fitz for heading detection
2. Run `HeaderFooterDetector.detect(doc)` -> header/footer patterns
3. Strip headers/footers from each page's text
4. Concatenate all page texts with page boundary tracking
5. Run `HeadingDetector.detect(doc)` -> heading hierarchy
6. Run `PDFChunker.chunk(full_text, headings, page_boundaries)` -> chunk dicts
7. For each chunk: build `PDFChunkMetadata`, compute chunk_id, create `ChunkPayload`
8. Batch embed chunks via `EmbeddingBackend.embed()`
9. Upsert to vector store via `VectorStoreBackend.upsert_chunks()`

**Key question:** HeadingDetector operates on `fitz.Document`, which requires the original PDF. For scanned PDFs (Type B), the PDF outline and font-based strategies may yield nothing (no text layer). The markdown strategy also requires text. So heading detection for OCR output may need to operate on the cleaned OCR text itself, not the original PDF. The chunker already accepts headings as `(level, title, char_offset)` tuples from any source.

**Decision:** For scanned PDFs, heading detection from the PDF outline should still be attempted (some scanned PDFs have OCR layers or bookmarks). Font-based detection will likely fail. Markdown detection will fail. If no headings found, chunk without heading awareness -- this is the expected case for scanned documents. The heading path in metadata will be `None` or `[]`.

### 10. LLM Cleanup (Step 7)

When `enable_ocr_cleanup=True`:
- Send postprocessed OCR text to `config.ocr_cleanup_model` via `LLMBackend.generate()`
- Prompt: "Fix obvious OCR errors while preserving meaning"
- Must handle: LLM unavailable (log warning, use unclean text), timeout, empty response
- LLM is optional (`llm: LLMBackend | None` in constructor)
- If `llm is None` and `enable_ocr_cleanup=True`, log warning and skip cleanup

## Key Decisions for PLAN

1. **Worker function design:** Module-level function that takes serializable args (file_path, page_number, ocr_dpi, preprocessing_steps, ocr_engine_name, ocr_language, enable_language_detection, default_language). Worker opens PDF, renders, preprocesses, detects language, runs OCR, postprocesses. Returns `OCRResult` or raises.

2. **Sequential fallback for testing:** Add `_ocr_pages_sequential()` and `_ocr_pages_parallel()` private methods. Parallel uses ProcessPoolExecutor. Tests can monkeypatch or the processor can fall back to sequential when `ocr_max_workers <= 1`.

3. **Page filtering:** Filter pages based on `pages` parameter (None = all) and `profile.pages[i].page_type`. Skip BLANK, TOC, VECTOR_ONLY pages with warnings. Process SCANNED, MIXED pages. TEXT pages should not normally arrive at Path B, but handle gracefully.

4. **Error handling per page:** If a single page fails OCR (timeout or error), record the error and continue with remaining pages. Do not abort the entire document for one page failure.

5. **Heading detection source:** Attempt PDF-based heading detection first (may find bookmarks). If empty, accept no headings -- scanned PDFs rarely have heading metadata.

6. **Metadata per chunk:** Include OCR-specific fields (ocr_engine, ocr_confidence as average across chunk's pages, ocr_dpi, ocr_preprocessing).

7. **LLM cleanup isolation:** Wrap in try/except. If LLM fails, log warning and continue with postprocessed (non-LLM-cleaned) text.

## Dependency Analysis

### All Dependencies Already Exist

**Internal (all implemented and tested):**
- `ingestkit_pdf.utils.page_renderer.PageRenderer`
- `ingestkit_pdf.utils.ocr_engines.create_ocr_engine`, `OCREngineInterface`, `OCRPageResult`, `EngineUnavailableError`
- `ingestkit_pdf.utils.ocr_postprocess.postprocess_ocr_text`
- `ingestkit_pdf.utils.language.detect_language`, `map_language_to_ocr`
- `ingestkit_pdf.utils.heading_detector.HeadingDetector`
- `ingestkit_pdf.utils.chunker.PDFChunker`
- `ingestkit_pdf.utils.header_footer.HeaderFooterDetector`
- `ingestkit_pdf.models.*` (OCRResult, OCRStageResult, ProcessingResult, PDFChunkMetadata, etc.)
- `ingestkit_pdf.config.PDFProcessorConfig`
- `ingestkit_pdf.errors.ErrorCode`, `IngestError`
- `ingestkit_pdf.protocols.VectorStoreBackend`, `EmbeddingBackend`, `LLMBackend`
- `ingestkit_core.models.ChunkPayload`, `WrittenArtifacts`, `EmbedStageResult`

**External (stdlib):**
- `concurrent.futures.ProcessPoolExecutor`, `as_completed`, `TimeoutError`
- `hashlib`, `uuid`, `time`, `logging`, `pathlib`

**External (third-party, already in deps):**
- `fitz` (PyMuPDF) -- for opening PDF to render pages and detect headings
- `PIL` (Pillow) -- images passed between renderer and OCR engine

### No New Dependencies Required

### Downstream Consumers
- `PDFRouter` (future issue) will instantiate and call `OCRProcessor.process()`
- `ComplexProcessor` (issue #40/future) will reuse OCR logic for SCANNED pages within complex documents

## File Inventory

### Files to Create

| File | Purpose | Est. Lines |
|------|---------|-----------|
| `packages/ingestkit-pdf/src/ingestkit_pdf/processors/ocr_processor.py` | OCRProcessor implementation | ~400-500 |
| `packages/ingestkit-pdf/tests/test_ocr_processor.py` | Full test suite | ~600-800 |

### Files to Modify

| File | Change |
|------|--------|
| `packages/ingestkit-pdf/src/ingestkit_pdf/processors/__init__.py` | Export `OCRProcessor` |
| `packages/ingestkit-pdf/src/ingestkit_pdf/__init__.py` | Add `OCRProcessor` to public exports |
| `packages/ingestkit-pdf/tests/conftest.py` | Add mock backends: `MockVectorStoreBackend`, `MockEmbeddingBackend`; extend `MockLLMBackend.generate()` |

### Files to Read Only (No Changes)

| File | Why |
|------|-----|
| `packages/ingestkit-pdf/src/ingestkit_pdf/models.py` | OCRResult, OCRStageResult, ProcessingResult, PDFChunkMetadata |
| `packages/ingestkit-pdf/src/ingestkit_pdf/config.py` | OCR config fields |
| `packages/ingestkit-pdf/src/ingestkit_pdf/errors.py` | Error codes |
| `packages/ingestkit-pdf/src/ingestkit_pdf/protocols.py` | Backend protocols |
| `packages/ingestkit-pdf/src/ingestkit_pdf/utils/*.py` | All utility modules |
| `packages/ingestkit-core/src/ingestkit_core/models.py` | ChunkPayload, WrittenArtifacts, EmbedStageResult |
| `packages/ingestkit-core/src/ingestkit_core/protocols.py` | Backend protocol signatures |
| `packages/ingestkit-excel/src/ingestkit_excel/processors/structured_db.py` | Pattern reference |

## Test Coverage Plan

### Mock Infrastructure Needed

1. **MockVectorStoreBackend**: tracks `upsert_chunks()` calls, stores chunks for assertion
2. **MockEmbeddingBackend**: returns deterministic vectors of correct dimension, tracks calls
3. **MockLLMBackend.generate()**: currently raises `NotImplementedError` -- needs implementation for OCR cleanup tests
4. **Mock fitz.Document/Page**: lightweight mocks that return predictable pixmaps and text data

### Test Classes

1. **TestOCRProcessorInit**: constructor accepts backends, config; handles None LLM
2. **TestSinglePageOCR**: end-to-end single scanned page -> chunks in vector store
3. **TestMultiPageOCR**: multiple pages, correct page boundaries, metadata propagation
4. **TestPageFiltering**: skips BLANK/TOC/VECTOR_ONLY pages with warnings; processes only specified pages via `pages` parameter
5. **TestParallelOCR**: verifies ProcessPoolExecutor usage with max_workers; sequential fallback when workers=1
6. **TestPerPageTimeout**: individual page timeout produces E_OCR_TIMEOUT error, remaining pages continue
7. **TestPerPageError**: individual page OCR failure recorded, processing continues
8. **TestLowConfidenceWarning**: pages below `ocr_confidence_threshold` flagged with W_PAGE_LOW_OCR_CONFIDENCE
9. **TestLLMCleanup**: cleanup called when enabled; skipped when disabled; skipped when LLM is None; handles LLM failure gracefully
10. **TestOCRStageResult**: correct pages_ocrd, avg_confidence, low_confidence_pages, engine_used, engine_fallback_used
11. **TestChunkMetadata**: PDFChunkMetadata has correct ocr_engine, ocr_confidence, ocr_dpi, ocr_preprocessing, ingestion_method="ocr_pipeline"
12. **TestBatchEmbedding**: chunks embedded in batches of embedding_batch_size
13. **TestProcessingResult**: fully assembled result with all fields, correct ingestion_method
14. **TestEngineUnavailable**: EngineUnavailableError produces E_OCR_ENGINE_UNAVAILABLE error
15. **TestEngineFallback**: PaddleOCR -> Tesseract fallback recorded in warnings and OCRStageResult
16. **TestLanguageDetection**: per-page language detection when enabled; default language when disabled
17. **TestHeaderFooterStripping**: headers/footers detected and stripped from OCR text
18. **TestHeadingDetection**: headings detected from PDF outline/fonts for scanned docs; empty headings handled
19. **TestEmptyOCROutput**: all pages produce empty text -> ProcessingResult with zero chunks

## Risk Assessment

- **Medium risk: ProcessPoolExecutor testability.** Multiprocessing is hard to unit test. Mitigation: extract worker function as module-level, test it independently; use `ocr_max_workers=1` for sequential path in most tests; integration tests for actual parallelism.
- **Medium risk: fitz.Page mocking.** PyMuPDF objects are complex C-extension types. Mitigation: use `unittest.mock.MagicMock` with spec, or create thin wrapper.
- **Low risk: All utilities are implemented and tested.** The processor is primarily orchestration.
- **Low risk: Model/config/error inventory is complete.** No missing types.

AGENT_RETURN: .agents/outputs/map-39-021426.md
